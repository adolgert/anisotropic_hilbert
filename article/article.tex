\documentclass{article}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{mathtools}      % For \coloneqq and other extensions
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{booktabs}       % For nice tables
\usepackage{array}
\usepackage{graphicx}
\usepackage{xspace}
\graphicspath{{figures/}}
\DeclareGraphicsExtensions{.pdf,.png,.jpg}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{enumitem}       % For customized lists
\usepackage{tikz}
\usetikzlibrary{arrows.meta, positioning}
\usepackage{geometry}
\geometry{
  left=0.75in,
  right=3in,
  top=0.5in,
  bottom=0.7in
}
\usepackage{setspace}
\onehalfspacing

% ============================================================================
% THEOREM ENVIRONMENTS
% ============================================================================
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{remark}[theorem]{Remark}

% ============================================================================
% CUSTOM COMMANDS FOR NOTATION
% ============================================================================
% Bit operations (matching Hamilton's notation)
\newcommand{\XOR}{\oplus\xspace}           % XOR: exclusive or
\newcommand{\AND}{\mathbin{\wedge}\xspace}            % AND
\newcommand{\OR}{\mathbin{\vee}\xspace}               % OR
\newcommand{\NOT}{\mathord{\sim}\xspace}              % NOT (bitwise complement)
\newcommand{\SHL}{\mathbin{\triangleleft}\xspace}     % Shift left
\newcommand{\SHR}{\mathbin{\triangleright}\xspace}    % Shift right
\newcommand{\ROTL}{\mathbin{\circlearrowleft}\xspace} % Rotate left
\newcommand{\ROTR}{\mathbin{\circlearrowright}\xspace}% Rotate right
\newcommand{\vplus}{\mathbin{\oplus}\xspace}   % plus
\newcommand{\vtimes}{\mathbin{\otimes}\xspace}

% Convenient shortcuts
\newcommand{\gc}{g\xspace}                  % Gray code function
\newcommand{\gcinv}{g^{-1}\xspace}          % Gray code inverse
\newcommand{\bitfn}{\mathrm{bit}\xspace}              % bit extraction function
\newcommand{\tsb}{\mathrm{tsb}\xspace}                % trailing set bits
\newcommand{\entry}{e\xspace}                % entry point function
\newcommand{\exitpt}{f\xspace}               % exit point function (f for "finish")
\newcommand{\dir}{d\xspace}                  % direction function
\newcommand{\gcr}{\mathrm{gcr}\xspace}                % Gray code rank
\newcommand{\order}{m_{\text{max}}\xspace}
\newcommand{\dk}{dk\xspace}
\newcommand{\embed}{\kappa\xspace}
\newcommand{\brgc}{BRGC\xspace}
% Sets
\newcommand{\Z}{\mathbb{Z}\xspace}                    % Integers
\newcommand{\N}{\mathbb{N}\xspace}                    % Natural numbers
\newcommand{\B}{\mathbb{B}\xspace}                    % Binary digits {0,1}

% Other
\newcommand{\encode}{\mathrm{encode}\xspace}
\newcommand{\decode}{\mathrm{decode}\xspace}


\title{Lattice-Continuous Compact Hilbert Indices via Affine Transformations on Hypercubes}
\author{Andrew Dolgert}
\date{\today}


\begin{document}
\maketitle
\begin{abstract}
Space-filling curves are fundamental to combinatorial optimization and multidimensional indexing.
Existing compact linearizations for unequal dimensions fail to preserve lattice continuity (adjacency), degrading locality.
We introduce a general construction using Gray codes and affine transformations in $\mathbb{F}_2^n$.
We prove this construction yields a lattice-continuous mapping for arbitrary dimension extents and provide an $O(mn)$ time algorithm.
\end{abstract}

\section{Introduction}

Space-filling curves are fundamental.

Recent interest in Hilbert curves: mesh refinement,
combinatorial optimization, multidimensional indexing. Use in AI.
They rely on continuity and search for better locality~\cite{franco2025pareto}.

Problems with unequal axes stem from presentation of gluing constraints.
Nice work in \cite{alber2000multidimensional}.

Locality depends on particular choice of Hilbert curve~\cite{haverkort2010locality}.
Would like to expand ability to use different Hilbert curves.

I don't love counting and staring at things when they are in $n$-dimensions.
Use $\mathbb{F}_2^n$ to stop staring.

\begin{itemize}
  \item Express gluing constaint in $\mathbb{F}_2^n$ for clarity.
  \item Give a dynamic program to construct valid orientation tables so that it is possible to generate new Hilbert curves quickly for any Gray code.
  \item Make unequal side lengths on better footing so they are lattice-continuous with less razzle-dazzle.
\end{itemize}

\section{Preliminaries}
\subsection{Hyperrectangle}
Let dimensions $n\ge 1$ and extents $\mathbf{m}=(m_0,\ldots,m_{n-1})\in \mathbb{N}^n$ define a hyperrectangle.
$$
  P_n(\mathbf{m})=\prod_{j=0}^{n-1}\left\{0,1,\ldots,2^{m_j}-1\right\}
$$
The sum of extents is $M=\sum_{j=0}^{n-1}m_j$.

\subsection{Lattice-continuous Hilbert Curve}

\begin{definition}[Lattice-continuous index]
  A bijection $H: P_n(\mathbf{m})\rightarrow \{0,1,\ldots,2^M-1\}$
  between a \emph{point} in $P(\mathbf{m})$ and an \emph{index} in $\mathbb{Z}$
  is \emph{lattice-continuous} if $||H^{-1}(t)-H^{-1}(t+1)||_1$
  for all $t\in\{0,1,\ldots,2^M-2\}$.
\end{definition}

\begin{definition}[Hilbert curve]
A Hilbert curve or order $m$ is a lattice-continuous index on $P_n(\mathbf{m})$
with $m=\max(\mathbf{m})$ and boundary conditions
$H(\mathbf{0})=0$ and $H((2^{m_j}-1)\mathbf{e}_j)2^M-1$ for some axis $j$.
\end{definition}

\subsection{Binary Hypercube}
Recursive algorithms for Hilbert curves partition each level using
binary hypercubes.

For $k\ge 1$, let $V_k=\mathbb{F}_2^k=\{0,1\}^k$ and identify it with the vertex
set of the $k$-dimensional hypercube $Q_k$. This space is equipped with
addition $\vplus$ and multiplication $\vtimes$ which correspond to
an XOR and AND operation on bit representations.

Vertices $u,v\in V_k$ are adjacent if $u\oplus v \in \{\mathbf{e}_0,\ldots,\mathbf{e}_{k-1}\}$ where $\mathbf{e}_j$ is a unit vector along the $j$ axis.


\subsection{Affine automorphisms and orientations}

A map $A : V_k\rightarrow V_k$ is an \emph{affine automorphism} of $Q_k$
if it is of the form $A(x)=Px\vplus a$ where $P$ is a coordinate permutation
matrix over $\mathbb{F}_2^k$ and $a\in V_k$. Affine automorphisms preserve adjacency.

Our main concern, however, will be the orientation of directed edges, where
a directed edge is a pair of position and direction, $(e\in V_k,d\in \{0,\ldots,k\})$.

\emph{Cyclic affine transformations} consist of a cyclid rotation $\rho$ and
a translation $e$.
$$
T_{e,d}(y)=\rho^d y \vplus e\qquad d\in \mathbb{Z}, e\in V_k
$$
These can transform any directed edge in $Q_k$ to any other directed edge but
do not include general permuations. The number of affine automorphisms
is $2^k\prod_{i=0}^{k-1}(2^k-2^i)$ versus the cyclic affine maps which number
$k2^k$~\cite{lidl1997finite}. For $k=3$, there are 1344~affine automorphisms and 24~cyclic affine maps.

Note that this definition of $T_{e,d}$ differs from that of Hamilton and
Rao-Chaplin becuase it rotates by $d$ rather than $d+1$.

\subsection{Binary Gray Codes}\label{sec:binary-gray}

A binary Gray code is a Hamiltonian path on $Q_k$ for $k\ge 1$. We represent
a Gray code as a bijection
$$
  G_k : \{0,1,\ldots,2^k-1\}\rightarrow V_k \quad R_k : V_k\rightarrow \{0,1,\ldots,2^k-1\}
$$
with $R_k=G_k^{-1}$ the rank of a point in $Q_k$. In $V_k$, there is a unique
axis
$$
  G_k(w) + G_k(w+1)=\mathbf{e}_{\sigma_k(w)}.
$$

The Hilbert algorithm will use the Gray code rank to determine the visiting
order within a hypercube. Of particular interest are the rank~$0$ and rank~$2^k-1$
elements of the hypercube because they determine adjacency as shown in Sec.~XXX.

There are many Gray codes but the rank~$2^k-1$ exit point will always be adjacent
to the rank~$0$ entry point according to Alber and Niedermeier~\cite{alber2000multidimensional}. It will be convenient to assume a base frame defined
by an origin and a primary axis.
$$
  G_k(0)=\mathbf{0} \quad G_k(2^k-1)=\mathbf{e}_0.
$$

The best-known Gray code, used by Butz and Hamilton among others~\cite{butz2006alternative,hamilton2006compact}, is the \emph{binary-reflected Gray code} (\brgc). This Gray code has closed-form expressions for $G_k$ and $R_k$ and is
\emph{linear} in $V_k$.
It's first element is at the origin, but its last element is in $\mathbf{e}_{k-1}$,
so we will consider it rotated by one, using $T_{\mathbf{0},-1}$, to meet the boundary conditions.
This rotation of the \brgc is a common, if implicit, assumption that can show up as a $+1$ in
initial conditions and later transformations~\cite{hamilton2008compact}.


\subsection{Bit plane decomposition}

We decompose the space $P(\mathbf{m})$ into levels $s\in \{m, m-1,\ldots,1\}$.
The level-$s$ bit-plane vector is the $(s-1)$-th bit of each coordinate of the
point in $P$.
The space of each level is $V_k$ where $k = |\{j : m_j \ge s\}| \le n$.
It is in this space, which defines how we recursively decompose the domain
of a Hilbert curve, that we define Gray codes and orient child levels.


\section{Hilbert curve construction with affine transforms}
The key is connecting orientation and adjacency.

We could do this with point-free language, but would you believe it?

A lattice-continuous Hilbert curve relies on continuity across decomposition
levels.

Claim: You can construct a Hilbert curve recursively from a Hilbert curve
and a Gray code equipped with a set of directed edges in $V_k$.

\subsection{high + low}
Consider a point domain of order $m=2$. Identify the level~2 decomposition
with a high bit $h\in V_2$ and the level~1 decomposition with a low bit
$\ell\in V_2$. We can make a map from $(V_2\times V_2) \rightarrow P_k(2)$.
$$
x = 2h +\ell \quad h,\ell \in V_k
$$
Rank the high bits with a Gray code so that the sequence
$h_w=R_k(w)$ for $w\in\{0,\ldots,2^k\}$
traverses all of the $2^k$ cubes in $P_k(2)$. Let $d_w\coloneq \sigma_k(w)$
so that $h_{w+1}=h_w\vplus \mathbf{e}_{d_w}$.

\subsection{entry + exit}
Our recursive construction means that, for a child hypercube, defined by having a fixed high bit $h_w$,
the low bit will itself traverse a Gray code, which guarantees lattice continuity
within the child.

There will be an entry and exit vertex for the $2^k$ points within the child domain.
As described in Sec.~\ref{sec:binary-gray}, the exit corner is a unit step $a_w$ from
the entrance corner. In the context of $P_k(2)$, we consider them in coordinate space.
$$
  \ell_w^{\text{out}} \coloneq \ell_w^{\text{in}}\vplus \mathbf{e}_{a_w}
$$

\subsection{gluing constraint}

Crossing from cube \(h_w\) to cube \(h_{w+1}=h_w\vplus\mathbf{e}_{d_w}\) happens across the shared face in axis \(d_w\).
In \((h,\ell)\)-coordinates, the unique lattice adjacency across that face flips both the high and low bits in axis \(d_w\).
Therefore, lattice continuity across the seam forces
\begin{equation}\label{eq:seam}
(h_{w+1},\ell^{\mathrm{in}}_{w+1}) = (h_w\vplus\mathbf{e}_{d_w},\;\ell^{\mathrm{out}}_w\vplus\mathbf{e}_{d_w}).
\end{equation}
Equivalently, in low-bit coordinates:
\begin{equation}\label{eq:glue-low}
\ell^{\mathrm{in}}_{w+1} = \ell^{\mathrm{in}}_w \vplus \mathbf{e}_{a_w} \vplus \mathbf{e}_{d_w}.
\end{equation}

\subsection{Induction}

We just demonstrated a concrete construction of a two-level curve.
Let's show that the same transforms from the two-level construction
apply to descent from level $s$ to level $s-1$.

Again we define a high and low, but the low is in $P_k(s)$.
\begin{equation}
x = 2^sh + \ell\quad h\in V_k, \ell\in P_k(s), 
\end{equation}
Treat $\l_w^{\text{in}}$ as a \emph{corner label} not the full $\ell\in P_k(s)$.

Lift the transforms $T_{e,d}$ to $P_k(s)$ by writing a coordinate in $P_k(s)$
as a sum of bit planes.
\begin{equation}
  \ell = \sum_{j=0}^{s-1}2^jb_j(\ell)\quad b_j(x)\in V_k
\end{equation}
Now define a lifted transform.
\begin{equation}
  \tilde{T}_{e,d}(x) \coloneq \sum_{j=0}^{s-1}2^j T_{e,d}(b_s(x))
\end{equation}
Because $\XOR$ with $e$ applied to every bit-plane complements the entire
$s$-bit word when $e_i=1$, the same map can be written coordinatewise.
\begin{equation}
  \left(\tilde{T}_{e,d}(x\right)_i = \left(x_{\rho^d(i)}\right)\vplus \left(e_i(2^s-1)\right)
\end{equation}
That is, for our boundary conditions, the translation in $T_{e,d}$ determines
whether the axis is flipped for $P_k(s)$.
\begin{equation}
  \left(\tilde{T}_{e,d}(x\right)_i = \begin{cases}
  x_{\rho^d(i)}, & \mathbf{e}_i=0 \\
  (2^j-1)-x_{\rho^d(i)}, & \mathbf{e}_i=1
  \end{cases}
\end{equation}
As with $T_{e,d}$, $\tilde{T}_{e,d}$ is a bijection, so it preserves
lattice adjacency within $P_k(s)$.

The gluing condition, Eq.~\ref{eq:glue-low}, remains true in this context
if we see it as a corner condition, so $\ell_w^{\text{in}}$ is a corner label.

The Hilbert curve becomes
\begin{equation}
  H_{s+1}(2^{ks}w + c)\coloneq 2^s h_w + \tau_w^(s)(H_j(s))
\end{equation}

Prove bijection: The sets $2^sh_w+P_k(s)$ are disjoint and cover $P_k(j+1)$
(standard dyadic partition). On each such set, $\tau_w^(s)\odot H_j$ is a bijection Since
$H_j$ is and $\tau_w^{s}$ is a bijection. So the concatenation visits every
point exactly once.

Seam adjacency: This reduces to the $\mathbb{F}_2^k$ gluing constraint.
The entry and exit points of consecutive subcubes are known by construction.
\begin{equation}
\begin{aligned}
X_w^{\text{out}} & = H_{s+1}((w+1)2^{ks}-1) \\
X_{w+1}^{\text{in}} & = H_{s+1}((w+1)2^{ks}) \\
\end{aligned}
\end{equation}

We can trace adjacency as before. When leaving one child hypercube to traverse
to another, one bit flips in the high bit, and one bit flips in the low bit.
Here, the bit flips in the low bit \emph{corner}, so it changes by $\vplus$
with $e_{d_w}$, in accordance with the seam constraint.

Geometrically: Stepping to the neighboring subcube along axis $d_w$ changes the
high contribution by $\pm 2^s \mathbf{e}_{d_w}$, and the low corner flips between
the two opposite faces (coordinate $0 \leftrightarrow 2^s-1$), changing the low
contribution by $\mp(2^s-1)\mathbf{e}_{d_w}$. Those two changes always sum to
$\pm 1e_{d_w}$, that is a distance~1 move.

\subsection{induction on gluing}

Base case is that a binary Gray code is a lattice-continuous Hilbert curve
on $P_k(1)$.

Once you have a path for $s_w$ it defines a set of transforms $\tau_w$
for the child hypercubes such that the entry and exit within the child's
space $V'_n$ orient to the parent's space $V_n$.
$$
  \ell_w^{\text{in}}=\tau_w \mathbf{0}\quad \ell_w^{\text{in}}=\tau_w \mathbf{e}_0
$$
A suffient set of transforms $\tau_w$ is the set of orientations of directed
edges above, $T_{e,d}$, where we can determine the unknown parameters $(e,d)$.
$$
\begin{aligned}
  \rho^d \mathbf{0} + e & = \ell_w^{\text{in}}\\
  \rho^d \mathbf{e}_0 + e & = \ell_w^{\text{out}}
\end{aligned}
$$
The result is that $e=\ell_w^{\text{in}}$ and $d=a_w=\ell_w^{\text{in}}+\ell_w^{\text{out}}$. We now have a new map from $(V_2\times V'_2) \rightarrow P(2)$.
$$
x = 2h + T_{e_w,d_w}(\ell) \quad h\in V_k, \ell\in V'_k
$$
where $w=R_k(h)$. The transform $T_{e_w,d_w}$ maps the child space into the
parent space.

Above we used boundary conditions to determine a valid path through $P_k(2)$.
They are that the first rank is the origin and the last rank is $(4,0,\ldots)$.
That shows that a two-level construction keeps the boundary conditions of a
correct one-level construction.

If the transforms that apply to this construction are applied to sub-hypercubes
of shape $P_k(n)$, where those sub-hypercubes have a curve defined that is
lattice-continuous with boundary conditions at the origin and at $(2^n-1)\mathbf{e}_0$,
then we can show that the construction above produces a lattice-continuous
Hilbert curve of shape $P_k(n+1)$ with boundary conditions at the origin and
at $(2^{n+1}-1)\mathbf{e}_0$.

World coordinates are associated with the highest level of decomposition.

\section{Directed Edges for any Gray Code}

Were we to know the set of transforms for a particular Gray code,
then we would have a Hilbert curve. Where do we get the transforms?
The most popular method is to construct a graph for the $P_k(2)$ case
and solve for all paths consistent with the Gray code's Hamiltonian path
and Hilbert boundary conditions. These methods work well, but there are strong
geometric constraints from subdivision of the space. These constraints suggest
there might be more structure in the problem, such as the interaction between
the high-bit coordinate and the low-bit coordinate.

\subsection{Mismatch}
\begin{lemma}[Mismatch-state form]\label{lem:mismatch}
Define the \emph{mismatch state} \(s_w\in V_k\) by
\begin{equation}\label{eq:mismatch}
 s_w \coloneqq h_w \vplus \ell^{\mathrm{in}}_w.
\end{equation}
Then \eqref{eq:glue-low} is equivalent to the pair of constraints
\begin{align}
 s_{w+1} &= s_w \vplus \mathbf{e}_{a_w}, \label{eq:s-walk}\\
 (s_{w+1})_{d_w} &= 1. \label{eq:s-face}
\end{align}
\end{lemma}

\begin{proof}
Using \eqref{eq:parent-step} and \eqref{eq:glue-low},
\[
\begin{aligned}
 s_{w+1}
 &= h_{w+1}\vplus \ell^{\mathrm{in}}_{w+1}
 = (h_w\vplus\mathbf{e}_{d_w}) \vplus (\ell^{\mathrm{in}}_w\vplus\mathbf{e}_{a_w}\vplus\mathbf{e}_{d_w})
 = (h_w\vplus\ell^{\mathrm{in}}_w)\vplus\mathbf{e}_{a_w}
 = s_w\vplus\mathbf{e}_{a_w},
\end{aligned}
\]
which is \eqref{eq:s-walk}.
For \eqref{eq:s-face}, note that \eqref{eq:seam} implies the seam vertex \((h_{w+1},\ell^{\mathrm{in}}_{w+1})\) lies on the shared face in axis \(d_w\), i.e. its low bit in axis \(d_w\) equals \(1-(h_{w+1})_{d_w}\).
Equivalently,
\((\ell^{\mathrm{in}}_{w+1})_{d_w} \vplus (h_{w+1})_{d_w} = 1\), which is \((s_{w+1})_{d_w}=1\).
\end{proof}

Lemma \ref{lem:mismatch} reduces the two-level gluing problem to a constrained walk on the hypercube \(Q_k\): at step \(w\), choose any neighbor \(s_{w+1}\) of \(s_w\) such that coordinate \(d_w\) of \(s_{w+1}\) is \(1\).

Recall that in Hamilton and Rao-Chaplin, the child walk is on $Q_{k-1}$
because of symmetry of the \brgc. We can show how to derive that
walk\dots

\subsection{existence}
Does a path in always exist? Yes! It's not hard to find, actually.

It's like a little board game. You roll the dice (follow the Gray code), and sometimes there is a
move you must do, while other times you have some choice.

Can we point out the calculation that shows why the \brgc path works?

\subsection{dynamic program}
Yup, it's running, and it's wicked fast. Just gotta write it here.

Given that we have a concise description of which paths are allowed through
$P_k(2)$, we can create an algorithm to generate them efficiently.


\section{Construction}


\subsection{Encode and decode for equal side lengths}

This is a recursive algorithm that starts at the level $s=m$ and progresses
to level $s=1$. The state at each level is defined by the
current bit plane and the transform $T_{e_s,d_s}$.

Start with the identity as the transform. Extract the bit plane $b_s$ for level $s$ from
input coordinates $p$. Transform them with $b'_s=T^{-1}_{e_s,d_s}(b_s)$. Rank them with $w_s=R(b'_s)$. Scatter that rank $w$ into the Hilbert index at $\rho^{m*(s-1)}w$.
Update the transform for the next level down so it conforms to the curve,
$$
T_{e_{s-1},d_{s-1}}=T_{e_w,d_w}T_{e_s,d_s}
$$
This is equivalent to $e_{s-1}=\rho^d e_s + e_w$ and $d_{s-1}=d_s + d_w$.

Decoding is similar. The recursion and state are the same. At each level,
extract from the Hilbert index the rank, $w_s$ for this level. Find the coordinate
with $b'_s=G(w_s)$. Convert that to the local coordinates with $T_{e_w,d_w}$,
and scatter the resulting coordinate in $V_k$ into the $s-1$ bit of the
point coordinates. Finally, update the transform state for the level below.

\subsection{Unequal high + low}

What happens when we have unequal side lengths? In this recursive description,
the higher levels will have fewer dimensions, as few as $k=1$. Before, we
presented a two-level model for $P_k(2)$. Imagine now we have $k$ dimensions
at level $s$ and $k-dk$ levels at dimension $s-1$. The low bits will be
$\ell\in V_{k+dk}$.

We can choose an embedding for the high bits, $\kappa_s : V_k \rightarrow V_{k+dk}$.
If we previously had a two-level curve, we now act on both sides of Eq.~XXX
with the embedding.
$$
\kappa_s x = 2\kappa_s h + \kappa_s T_{e_w,d_w}(\kappa^{-1}_s\ell) \quad h\in V_k, \ell\in V'_{k+dk}
$$
Here, $\kappa_s^{-1}$ is the left-inverse of $\kappa_s$. In order to match
boundary conditions, we require that $\kappa_s^{-1}\mathbf{0}_{k+dk}=\mathbf{0}_{k}$
and that $\kappa_s^{-1}\mathbf{e}_{0,k+dk}=\mathbf{e}_{0,k}$. This may require
rotation of axes.

Because of the embedding, the boundary conditions remain associated with
the highest level of the decomposition, even if the origin of the coordinate
system changes as levels descend.

\subsection{Unequal encode and decode}

You can imagine the case where the extents are $(2,3,2)$ so that at level
$s=2$ the origin at the lower level is in $e_0$ in $V_3$ whereas the origin
at the parent level naturally at $e_1$ in $V_3$.

There is a convenient solution to the bookkeeping. At the start of the
calculation, order axes so that $m_0<m_1<\cdots m_{n-1}$. This way the
embedding won't shift the boundary conditions at $\mathbf{0}$ and $\mathbf{e}_0$
because the axis at 0 stays active.

If you want to use an arbitrary embedding, you can do it.

This does, however, mean that the algorithm for unequal side lengths has a 
different embedding operator. Whereas before for equal sides the operator
was $T^k_{e_w,d_w}$ it is now $T^{k+ds}_{e_w,d_w}$ which is the same offset now
embedded in the larger space and the same amount of circular rotation but embedded
into the larger space.

There is otherwise no change to the algorithm.

\subsection{Next index}

It is tremendously valuable to be able to map a whole domain $P_k(\mathbf{m})$
to its Hilbert indices. That calculation greatly reduces the total amount
of computation compared to computing each Hilbert index separately.

Maintain a stack of transforms $(e_s,d_s)$ and current rankings $w_s$.
Walk $w_s$ for each child cube.

This reduces the total computation to about $8+10k$ integer operations per
index. And more memory.

Finding the neighboring point in $P_k(\mathbf{m})$ is doable, and there is some
advantage, but it's much less helpful. We can calculate or measure how much
less helpful it is.

Prefix scan algorithm. Could the linearity of the BRGC and its transforms
mean that we can incrementally update the index given an incremental change
to the point?

\section{Experimental Validation}

\begin{table}[htbp]
\centering
\caption{Hilbert Curve Variants for Experiments}
\label{tab:curve-variants}
\begin{tabular}{c p{3cm} c c c p{3cm}}
\hline
Label & Construction & Gray code & Transforms & Lattice continuous & Notes \\
\hline
Hamilton-CHI & Removal of inactive indices & \brgc & Hamilton's $T_{e,d}$ & No & Algorithm from Hamilton and Rao-Chaplin~\cite{hamilton2008compact}. \\
\hline
LC-BRGC & This article & \brgc & Tabular & Yes & Uses \brgc but solves for the transforms \\
\hline
LC-Balanced & This article & Balanced & Tabular & Yes & The best known variant for locality \\
\hline
LC-Random & This article & Random & Tabular & Yes & As a robustness check \\
\hline
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Selected Domains for Experiments}
\label{tab:domains}
\begin{tabular}{lrrrrr}
\hline
Domain ID & $m=(m_x,m_y)$ & Grid size & Aspect Ratio & Total bits $M$ & Points $N=2^M$ \\
\hline
D0 & (9,9) & 512 x 512 & 1 : 1 & 18 & 262,144 \\
D1 & (11, 7) & 2048 x 128 & 16 : 1 & 18 & 262,144 \\
D2 & (12, 6) & 4096 x 64 & 64 : 1 & 18 & 262,144 \\
D3 & (13, 5) & 8192 x 32 & 256 : 1 & 18 & 262,144 \\
\hline
\end{tabular}
\end{table}

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{discontinuities_by_perimeter_2d}
\caption{Size of the largest discontinuity by perimeter for 2D domains for Compact Hilbert Indices
from Hamilton and Rao-Chaplin~\cite{hamilton2008compact}.}
\label{fig:discontinuities-perimeter-2d}
\end{figure}

\begin{table}[htbp]
\centering
\label{tab:locality-metrics}
\begin{tabular}{llrrrr}
\toprule
Domain & Aspect & Hamilton $\mathrm{WL}_\infty$ & LC-CHI $\mathrm{WL}_\infty$ & Hamilton WBA & LC-CHI WBA \\
\midrule
$512 \times 512$   & 1:1   & 4.75 & 4.75  & 2.29 & 2.29 \\
$2048 \times 128$  & 16:1  & 442  & 4.75  & 435  & 2.29 \\
$4096 \times 64$   & 64:1  & 384  & 7.62  & 416  & 2.29 \\
$8192 \times 32$   & 256:1 & 512  & 26.2  & 528  & 2.33 \\
\bottomrule
\end{tabular}
\caption{Worst-case locality metrics for Hamilton-CHI and LC-BRGC across rectangular domains.
Key metrics: $\mathrm{WL}_\infty$ (Chebyshev locality), $\mathrm{WL}_2$ (Euclidean locality),
$\mathrm{WL}_1$ (Manhattan locality), WBA (bounding box area ratio), WBP (bounding box perimeter ratio).}
\end{table}


\begin{table}[htpb]
\centering
\label{tab:bounding-box-stats}
\begin{tabular}{llrrrrr}
\toprule
Domain & Curve & Block size $B$ & Mean $\frac{\text{bbox}}{B}$ & P95 $\frac{\text{bbox}}{B}$ & Max $\frac{\text{bbox}}{B}$ & Max $\frac{\text{peri}}{\sqrt{B}}$ \\
\midrule
512$\times$512 & Hamilton & 32 & 1 & 1 & 1 & 4.24 \\
 & LC-BRGC & 32 & 1 & 1 & 1 & 4.24 \\
 & Hamilton & 100 & 1.35 & 1.68 & 1.92 & 5.6 \\
 & LC-BRGC & 100 & 1.35 & 1.68 & 1.92 & 5.6 \\
 & Hamilton & 500 & 1.41 & 1.79 & 2.05 & 5.72 \\
 & LC-BRGC & 500 & 1.41 & 1.79 & 2.05 & 5.72 \\
 & Hamilton & 1024 & 1 & 1 & 1 & 4 \\
 & LC-BRGC & 1024 & 1 & 1 & 1 & 4 \\
\addlinespace
2048$\times$128 & Hamilton & 32 & 1 & 1 & 1 & 4.24 \\
 & LC-BRGC & 32 & 1 & 1 & 1 & 4.24 \\
 & Hamilton & 100 & 2.33 & 1.68 & 174.08 & 52.8 \\
 & LC-BRGC & 100 & 1.35 & 1.68 & 1.92 & 5.6 \\
 & Hamilton & 500 & 2.43 & 2.05 & 40.96 & 25.76 \\
 & LC-BRGC & 500 & 1.41 & 1.79 & 2.05 & 5.72 \\
 & Hamilton & 1024 & 1 & 1 & 1 & 4 \\
 & LC-BRGC & 1024 & 1 & 1 & 1 & 4 \\
\addlinespace
4096$\times$64 & Hamilton & 32 & 1 & 1 & 1 & 4.24 \\
 & LC-BRGC & 32 & 1 & 1 & 1 & 4.24 \\
 & Hamilton & 100 & 2.38 & 1.92 & 51.2 & 28.8 \\
 & LC-BRGC & 100 & 1.35 & 1.68 & 1.92 & 5.6 \\
 & Hamilton & 500 & 2.45 & 10.24 & 10.24 & 12.88 \\
 & LC-BRGC & 500 & 1.4 & 1.79 & 2.05 & 5.72 \\
 & Hamilton & 1024 & 1 & 1 & 1 & 4 \\
 & LC-BRGC & 1024 & 1 & 1 & 1 & 4 \\
\addlinespace
8192$\times$32 & Hamilton & 32 & 1 & 1 & 1 & 4.24 \\
 & LC-BRGC & 32 & 1 & 1 & 1 & 4.24 \\
 & Hamilton & 100 & 2.39 & 12.8 & 12.8 & 14.4 \\
 & LC-BRGC & 100 & 1.34 & 1.68 & 1.92 & 5.6 \\
 & Hamilton & 500 & 2.31 & 4.1 & 4.1 & 8.59 \\
 & LC-BRGC & 500 & 1.49 & 2.05 & 2.05 & 5.72 \\
 & Hamilton & 1024 & 1 & 1 & 1 & 4 \\
 & LC-BRGC & 1024 & 1 & 1 & 1 & 4 \\
\bottomrule
\end{tabular}
\caption{This is the “indexing application” table. It is more intuitive than 
WBA/WBP
WBA/WBP and more directly tied to how SFCs are used to build blocks (e.g., R-tree leaves). Haverkort motivates this style of evaluation by grouping consecutive points into blocks and measuring block bounding boxes. Computation: deterministic (no sampling) if you just partition the full curve into consecutive blocks of size B. Report both average and max because seam jumps tend to show up in the max/tails.}
\end{table}

\begin{table}[htpb]
\centering
\label{tab:range-query}
\begin{tabular}{lrrrrl}
\toprule
Curve & Query window & Mean clusters & P95 clusters & Max clusters & Method \\
\midrule
Hamilton & 4$\times$4 & 3.97 & 6 & 7 & exhaustive (249,673) \\
LC-BRGC & 4$\times$4 & 3.97 & 6 & 6 & exhaustive (249,673) \\
LC-Balanced & 4$\times$4 & 3.97 & 6 & 6 & exhaustive (249,673) \\
LC-Random & 4$\times$4 & 3.97 & 6 & 6 & exhaustive (249,673) \\
\addlinespace
Hamilton & 8$\times$8 & 7.92 & 13 & 14 & exhaustive (233,073) \\
LC-BRGC & 8$\times$8 & 7.94 & 13 & 14 & exhaustive (233,073) \\
LC-Balanced & 8$\times$8 & 7.94 & 13 & 14 & exhaustive (233,073) \\
LC-Random & 8$\times$8 & 7.94 & 13 & 14 & exhaustive (233,073) \\
\addlinespace
Hamilton & 16$\times$16 & 15.83 & 26 & 29 & exhaustive (199,969) \\
LC-BRGC & 16$\times$16 & 15.85 & 26 & 26 & exhaustive (199,969) \\
LC-Balanced & 16$\times$16 & 15.85 & 26 & 26 & exhaustive (199,969) \\
LC-Random & 16$\times$16 & 15.85 & 26 & 26 & exhaustive (199,969) \\
\addlinespace
Hamilton & 64$\times$4 & 33.64 & 53 & 55 & exhaustive (246,013) \\
LC-BRGC & 64$\times$4 & 33.56 & 54 & 59 & exhaustive (246,013) \\
LC-Balanced & 64$\times$4 & 33.56 & 54 & 59 & exhaustive (246,013) \\
LC-Random & 64$\times$4 & 33.56 & 54 & 59 & exhaustive (246,013) \\
\addlinespace
Hamilton & 4$\times$64 & 32.06 & 52 & 60 & exhaustive (4,093) \\
LC-BRGC & 4$\times$64 & 31.99 & 51 & 51 & exhaustive (4,093) \\
LC-Balanced & 4$\times$64 & 31.99 & 51 & 51 & exhaustive (4,093) \\
LC-Random & 4$\times$64 & 31.99 & 51 & 51 & exhaustive (4,093) \\
\addlinespace
Hamilton & 32$\times$32 & 31.47 & 50 & 54 & exhaustive (134,145) \\
LC-BRGC & 32$\times$32 & 31.57 & 50 & 53 & exhaustive (134,145) \\
LC-Balanced & 32$\times$32 & 31.57 & 50 & 53 & exhaustive (134,145) \\
LC-Random & 32$\times$32 & 31.57 & 50 & 53 & exhaustive (134,145) \\
\bottomrule
\end{tabular}
\caption{This is a range query, done by exhaustive enumeration. This counts the number of clusters within a query window, but it doesn't count the size
of the gaps, so it doesn't differentiate strongly between breaks in locality
and large adjacency skips~\cite{moon2001analysis}.}
\end{table}


\section{Conclusion}
We have a new algorithm to find Hilbert curves.

We have a new algorithm to generate a sequence of points ranked
by their Hilbert index.

We have a new algorithm to construct Hilbert curves of unequal side
lengths that are lattice-continuous.


\bibliographystyle{plain}
\bibliography{article}

\end{document}
