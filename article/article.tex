\documentclass{article}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{mathtools}      % For \coloneqq and other extensions
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{booktabs}       % For nice tables
\usepackage{array}
\usepackage{graphicx}
\graphicspath{{figures/}}
\DeclareGraphicsExtensions{.pdf,.png,.jpg}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{enumitem}       % For customized lists
\usepackage{tikz}
\usetikzlibrary{arrows.meta, positioning}
\usepackage{geometry}
\geometry{
  left=0.75in,
  right=3in,
  top=0.5in,
  bottom=0.7in
}
\usepackage{setspace}
\onehalfspacing

% ============================================================================
% THEOREM ENVIRONMENTS
% ============================================================================
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{remark}[theorem]{Remark}

% ============================================================================
% CUSTOM COMMANDS FOR NOTATION
% ============================================================================
% Bit operations (matching Hamilton's notation)
\newcommand{\XOR}{\oplus}           % XOR: exclusive or
\newcommand{\AND}{\mathbin{\wedge}}            % AND
\newcommand{\OR}{\mathbin{\vee}}               % OR
\newcommand{\NOT}{\mathord{\sim}}              % NOT (bitwise complement)
\newcommand{\SHL}{\mathbin{\triangleleft}}     % Shift left
\newcommand{\SHR}{\mathbin{\triangleright}}    % Shift right
\newcommand{\ROTL}{\mathbin{\circlearrowleft}} % Rotate left
\newcommand{\ROTR}{\mathbin{\circlearrowright}}% Rotate right
\newcommand{\vplus}{\mathbin{\oplus}}   % plus
\newcommand{\vtimes}{\mathbin{\otimes}}

% Convenient shortcuts
\newcommand{\gc}{g}                  % Gray code function
\newcommand{\gcinv}{g^{-1}}          % Gray code inverse
\newcommand{\bitfn}{\mathrm{bit}}              % bit extraction function
\newcommand{\tsb}{\mathrm{tsb}}                % trailing set bits
\newcommand{\entry}{e}                % entry point function
\newcommand{\exitpt}{f}               % exit point function (f for "finish")
\newcommand{\dir}{d}                  % direction function
\newcommand{\gcr}{\mathrm{gcr}}                % Gray code rank
\newcommand{\order}{m_{\text{max}}}
\newcommand{\dk}{dk}
\newcommand{\embed}{\kappa}
\newcommand{\brgc}{BRGC}
% Sets
\newcommand{\Z}{\mathbb{Z}}                    % Integers
\newcommand{\N}{\mathbb{N}}                    % Natural numbers
\newcommand{\B}{\mathbb{B}}                    % Binary digits {0,1}

% Other
\newcommand{\encode}{\mathrm{encode}}
\newcommand{\decode}{\mathrm{decode}}


\title{Lattice-Continuous Compact Hilbert Indices via Affine Transformations on Hypercubes}
\author{Andrew Dolgert}
\date{\today}


\begin{document}
\maketitle
\begin{abstract}
Space-filling curves are fundamental to combinatorial optimization and multidimensional indexing.
Existing compact linearizations for unequal dimensions fail to preserve lattice continuity (adjacency), degrading locality.
We introduce a general construction using Gray codes and affine transformations in $\mathbb{F}_2^n$.
We prove this construction yields a lattice-continuous mapping for arbitrary dimension extents and provide an $O(mn)$ time algorithm.
\end{abstract}

\section{Introduction}

Space-filling curves are fundamental.

Recent interest in Hilbert curves: mesh refinement,
combinatorial optimization, multidimensional indexing. Use in AI.
They rely on continuity and search for better locality~\cite{franco2025pareto}.

Problems with unequal axes stem from presentation of gluing constraints.
Nice work in \cite{alber2000multidimensional}.

Locality depends on particular choice of Hilbert curve~\cite{haverkort2010locality}.
Would like to expand ability to use different Hilbert curves.

I don't love counting and staring at things when they are in $n$-dimensions.
Use $\mathbb{F}_2^n$ to stop staring.



\subsection{Hyperrectangle}
Let dimensions $n\ge 1$ and extents $\mathbf{m}=(m_0,\ldots,m_{n-1})\in \mathbb{N}^n$ define a hyperrectangle.
$$
  P_n(\mathbf{m})=\prod_{j=0}^{n-1}\left\{0,1,\ldots,2^{m_j}-1\right\}
$$
The sum of extents is $M=\sum_{j=0}^{n-1}m_j$.

\subsection{Lattice-continuous Hilbert Curve}

\begin{definition}[Lattice-continuous index]
  A bijection $H: P_n(\mathbf{m})\rightarrow \{0,1,\ldots,2^M-1\}$
  between a \emph{point} in $P(\mathbf{m})$ and an \emph{index} in $\mathbb{Z}$
  is \emph{lattice-continuous} if $||H^{-1}(t)-H^{-1}(t+1)||_1$
  for all $t\in\{0,1,\ldots,2^M-2\}$.
\end{definition}

The \emph{order} of a Hilbert curve is $m=\max(\mathbf{m})$.

\subsection{Binary Hypercube}
Recursive algorithms for Hilbert curves partition each level using
binary hypercubes.

For $k\ge 1$, let $V_k=\mathbb{F}_2^k$ and identify it with the vertex
set of the $k$-dimensional hypercube $Q_k$. This space is equipped with
addition $\vplus$ and multiplication $\vtimes$ which correspond to
an XOR and AND operation on bit representations.

Vertices $u,v\in V_k$ are adjacent if $u\oplus v \in \{\mathbf{e}_0,\ldots,\mathbf{e}_{k-1}\}$ where $\mathbf{e}_j$ is a unit vector along the $j$ axis.


\subsection{Affine automorphisms and orientations}

A map $A : V_k\rightarrow V_k$ is an \emph{affine automorphism} of $Q_k$
if it is of the form $A(x)=Px\vplus a$ where $P$ is a coordinate permutation
matrix over $\mathbf{F}_2^k$ and $a\in V_k$. Affine automorphisms preserve adjacency.

If we restrict $A$ to cyclic rotations of axes, $\rho$, then the set of
transformations
$$
T_{e,d}(y)=\rho^d y \vplus e
$$
where $d\in \mathbb{Z}$ and $e\in V_k$ can transform any directed edge in $Q_k$
to any other directed edge.

Note that this definition of $T_{e,d}$ differs from that of Hamilton and
Rao-Chaplin becuase it rotates by $d$ rather than $d+1$.

\subsection{Binary Gray Codes}\label{sec:binary-gray}

A binary Gray code is a Hamiltonian path on $Q_k$ for $k\ge 1$. We represent
a Gray code as a bijection
$$
  G_k : \{0,1,\ldots,2^k-1\}\rightarrow V_k \quad R_k : V_k\rightarrow \{0,1,\ldots,2^k-1\}
$$
with $R_k=G_k^{-1}$ the rank of a point in $Q_k$. In $V_k$, there is a unique
axis
$$
  G_k(w) + G_k(w+1)=\mathbf{e}_{\sigma_k(w)}.
$$

The Hilbert algorithm will use the Gray code rank to determine the visiting
order within a hypercube. Of particular interest are the rank~$0$ and rank~$2^k-1$
elements of the hypercube because they determine adjacency as shown in Sec.~XXX.

There are many Gray codes but the rank~$2^k-1$ exit point will always be adjacent
to the rank~$0$ entry point according to Alber and Niedermeier~\cite{alber2000multidimensional}. It will be convenient to assume the boundary conditions
$$
  G_k(0)=\mathbf{0} \quad G_k(2^k-1)=\mathbf{e}_0.
$$

The best-known Gray code, used by Butz and Hamilton among others~\cite{butz2006alternative,hamilton2006compact}, is the \emph{binary-reflected Gray code} (\brgc). This Gray code has closed-form expressions for $G_k$ and $R_k$.
It's first element is at the origin, but its last element is in $\mathbf{e}_{k-1}$,
so we will consider it rotated by one, using $T_{\mathbf{0},-1}$, to meet the boundary conditions.
This rotation of the \brgc is a common, if implicit, assumption that can show up as a $+1$ in
initial conditions and later transformations~\cite{hamilton2008compact}.


\subsection{Bit plane decomposition}

We decompose the space $P(\mathbf{m})$ into levels $s\in \{m, m-1,\ldots,1\}$.
The level-$s$ bit-plane vector is the $(s-1)$-th bit of each coordinate of the
point in $P$.
The space of each level is $V_k$ where $k = |\{j : m_j \ge s\}| \le n$.
It is in this space, which defines how we recursively decompose the domain
of a Hilbert curve, that we define Gray codes and orient child levels.


\section{Gluing in $4^k$}
The key is connecting orientation and adjacency.

A lattice-continuous Hilbert curve relies on continuity across decomposition
levels.

\subsection{high + low}
Consider a point domain of order $m=2$. Identify the level~2 decomposition
with a high bit $h\in V_2$ and the level~1 decomposition with a low bit
$\ell\in V_2$. We can make a map from $(V_2\times V_2) \rightarrow P_k(2)$.
$$
x = 2h +\ell \quad h,\ell \in V_k
$$
Rank the high bits with a Gray code so that the sequence
$h_w=R_k(w)$ for $w\in\{0,\ldots,2^k\}$
traverses all of the $2^k$ cubes in $P_k(2)$. Let $d_w\coloneq \sigma_k(w)$
so that $h_{w+1}=h_w\vplus \mathbf{e}_{d_w}$.

\subsection{entry + exit}
Our recursive construction means that, for a child hypercube, defined by having a fixed high bit $h_w$,
the low bit will itself traverse a Gray code, which guarantees lattice continuity
within the child.

There will be an entry and exit vertex for the $2^k$ points within the child domain.
As described in Sec.~\ref{sec:binary-gray}, the exit corner is a unit step $a_w$ from
the entrance corner. In the context of $P_k(2)$, we consider them in coordinate space.
$$
  \ell_w^{\text{out}} \coloneq \ell_w^{\text{in}}\vplus \mathbf{e}_{a_w}
$$

\subsection{gluing constraint}

Crossing from cube \(h_w\) to cube \(h_{w+1}=h_w\vplus\mathbf{e}_{d_w}\) happens across the shared face in axis \(d_w\).
In \((h,\ell)\)-coordinates, the unique lattice adjacency across that face flips both the high and low bits in axis \(d_w\).
Therefore, lattice continuity across the seam forces
\begin{equation}\label{eq:seam}
(h_{w+1},\ell^{\mathrm{in}}_{w+1}) = (h_w\vplus\mathbf{e}_{d_w},\;\ell^{\mathrm{out}}_w\vplus\mathbf{e}_{d_w}).
\end{equation}
Equivalently, in low-bit coordinates:
\begin{equation}\label{eq:glue-low}
\ell^{\mathrm{in}}_{w+1} = \ell^{\mathrm{in}}_w \vplus \mathbf{e}_{a_w} \vplus \mathbf{e}_{d_w}.
\end{equation}

\begin{lemma}[Mismatch-state form]\label{lem:mismatch}
Define the \emph{mismatch state} \(s_w\in V_k\) by
\begin{equation}\label{eq:mismatch}
 s_w \coloneqq h_w \vplus \ell^{\mathrm{in}}_w.
\end{equation}
Then \eqref{eq:glue-low} is equivalent to the pair of constraints
\begin{align}
 s_{w+1} &= s_w \vplus \mathbf{e}_{a_w}, \label{eq:s-walk}\\
 (s_{w+1})_{d_w} &= 1. \label{eq:s-face}
\end{align}
\end{lemma}

\begin{proof}
Using \eqref{eq:parent-step} and \eqref{eq:glue-low},
\[
\begin{aligned}
 s_{w+1}
 &= h_{w+1}\vplus \ell^{\mathrm{in}}_{w+1}
 = (h_w\vplus\mathbf{e}_{d_w}) \vplus (\ell^{\mathrm{in}}_w\vplus\mathbf{e}_{a_w}\vplus\mathbf{e}_{d_w})
 = (h_w\vplus\ell^{\mathrm{in}}_w)\vplus\mathbf{e}_{a_w}
 = s_w\vplus\mathbf{e}_{a_w},
\end{aligned}
\]
which is \eqref{eq:s-walk}.
For \eqref{eq:s-face}, note that \eqref{eq:seam} implies the seam vertex \((h_{w+1},\ell^{\mathrm{in}}_{w+1})\) lies on the shared face in axis \(d_w\), i.e. its low bit in axis \(d_w\) equals \(1-(h_{w+1})_{d_w}\).
Equivalently,
\((\ell^{\mathrm{in}}_{w+1})_{d_w} \vplus (h_{w+1})_{d_w} = 1\), which is \((s_{w+1})_{d_w}=1\).
\end{proof}

Lemma \ref{lem:mismatch} reduces the two-level gluing problem to a constrained walk on the hypercube \(Q_k\): at step \(w\), choose any neighbor \(s_{w+1}\) of \(s_w\) such that coordinate \(d_w\) of \(s_{w+1}\) is \(1\).

Recall that in Hamilton and Rao-Chaplin, the child walk is on $Q_{k-1}$
because of symmetry of the \brgc. We can show how to derive that
walk\dots

\subsection{existence}
Does a path in always exist? Yes! It's not hard to find, actually.

\subsection{dynamic program}

\section{Construction}
\subsection{induction on gluing}

Once you have a path for $s_w$ it defines a set of transforms $\tau_w$
for the child hypercubes such that the entry and exit within the child's
space $V'_n$ orient to the parent's space $V_n$.
$$
  \ell_w^{\text{in}}=\tau_w \mathbf{0}\quad \ell_w^{\text{in}}=\tau_w \mathbf{e}_0
$$
A suffient set of transforms $\tau_w$ is the set of orientations of directed
edges above, $T_{e,d}$, where we can determine the unknown parameters $(e,d)$.
$$
\begin{aligned}
  \rho^d \mathbf{0} + e & = \ell_w^{\text{in}}\\
  \rho^d \mathbf{e}_0 + e & = \ell_w^{\text{out}}
\end{aligned}
$$
The result is that $e=\ell_w^{\text{in}}$ and $d=a_w=\ell_w^{\text{in}}+\ell_w^{\text{out}}$. We now have a new map from $(V_2\times V'_2) \rightarrow P(2)$.
$$
x = 2h + T_{e_w,d_w}(\ell) \quad h\in V_k, \ell\in V'_k
$$
where $w=R_k(h)$. The transform $T_{e_w,d_w}$ maps the child space into the
parent space.

Above we used boundary conditions to determine a valid path through $P_k(2)$.
They are that the first rank is the origin and the last rank is $(4,0,\ldots)$.
That shows that a two-level construction keeps the boundary conditions of a
correct one-level construction.

\subsection{Encode and decode for equal side lengths}

This is a recursive algorithm that starts at the level $s=m$ and progresses
to level $s=1$. The state at each level is defined by the
current bit plane and the transform $T_{e_s,d_s}$.

Start with the identity as the transform. Extract the bit plane $b_s$ for level $s$ from
input coordinates $p$. Transform them with $b'_s=T^{-1}_{e_s,d_s}(b_s)$. Rank them with $w_s=R(b'_s)$. Scatter that rank $w$ into the Hilbert index at $\rho^{m*(s-1)}w$.
Update the transform for the next level down so it conforms to the curve,
$$
T_{e_{s-1},d_{s-1}}=T_{e_w,d_w}T_{e_s,d_s}
$$
This is equivalent to $e_{s-1}=\rho^d e_s + e_w$ and $d_{s-1}=d_s + d_w$.

Decoding is similar. The recursion and state are the same. At each level,
extract from the Hilbert index the rank, $w_s$ for this level. Find the coordinate
with $b'_s=G(w_s)$. Convert that to the local coordinates with $T_{e_w,d_w}$,
and scatter the resulting coordinate in $V_k$ into the $s-1$ bit of the
point coordinates. Finally, update the transform state for the level below.

\subsection{Unequal high + low}

What happens when we have unequal side lengths? In this recursive description,
the higher levels will have fewer dimensions, as few as $k=1$. Before, we
presented a two-level model for $P_k(2)$. Imagine now we have $k$ dimensions
at level $s$ and $k-dk$ levels at dimension $s-1$. The low bits will be
$\ell\in V_{k+dk}$.

We can choose an embedding for the high bits, $\kappa_s : V_k \rightarrow V_{k+dk}$.
If we previously had a two-level curve, we now act on both sides of Eq.~XXX
with the embedding.
$$
\kappa_s x = 2\kappa_s h + \kappa_s T_{e_w,d_w}(\kappa^{-1}_s\ell) \quad h\in V_k, \ell\in V'_{k+dk}
$$
Here, $\kappa_s^{-1}$ is the left-inverse of $\kappa_s$. In order to match
boundary conditions, we require that $\kappa_s^{-1}\mathbf{0}_{k+dk}=\mathbf{0}_{k}$
and that $\kappa_s^{-1}\mathbf{e}_{0,k+dk}=\mathbf{e}_{0,k}$. This may require
rotation of axes.

\subsection{Unequal encode and decode}

You can imagine the case where the extents are $(2,3,2)$ so that at level
$s=2$ the origin at the lower level is in $e_0$ in $V_3$ whereas the origin
at the parent level naturally at $e_1$ in $V_3$.

There is a convenient solution to the bookkeeping. At the start of the
calculation, order axes so that $m_0<m_1<\cdots m_{n-1}$. This way the
embedding won't shift the boundary conditions at $\mathbf{0}$ and $\mathbf{e}_0$
because the axis at 0 stays active.

This does, however, mean that the algorithm for unequal side lengths has a 
different embedding operator. Whereas before for equal sides the operator
was $T^k_{e_w,d_w}$ it is now $T^{k+ds}_{e_w,d_w}$ which is the same offset now
embedded in the larger space and the same amount of circular rotation but embedded
into the larger space.

There is otherwise no change to the algorithm.

\subsection{Next index}

It is tremendously valuable to be able to map a whole domain $P_k(\mathbf{m})$
to its Hilbert indices. That calculation greatly reduces the total amount
of computation compared to computing each Hilbert index separately.

Maintain a stack of transforms $(e_s,d_s)$ and current rankings $w_s$.
Walk $w_s$ for each child cube.

This reduces the total computation to about $8+10k$ integer operations per
index.

\section{Experimental Validation}

\begin{table}[htbp]
\centering
\caption{Hilbert Curve Variants for Experiments}
\label{tab:curve-variants}
\begin{tabular}{c p{3cm} c c c p{3cm}}
\hline
Label & Construction & Gray code & Transforms & Lattice continuous & Notes \\
\hline
Hamilton-CHI & Removal of inactive indices & \brgc & Hamilton's $T_{e,d}$ & No & Algorithm from Hamilton and Rao-Chaplin~\cite{hamilton2008compact}. \\
\hline
LC-BRGC & This article & \brgc & Tabular & Yes & Uses \brgc but solves for the transforms \\
\hline
LC-Balanced & This article & Balanced & Tabular & Yes & The best known variant for locality \\
\hline
LC-Random & This article & Random & Tabular & Yes & As a robustness check \\
\hline
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Selected Domains for Experiments}
\label{tab:domains}
\begin{tabular}{lrrrrr}
\hline
Domain ID & $m=(m_x,m_y)$ & Grid size & Aspect Ratio & Total bits $M$ & Points $N=2^M$ \\
\hline
D0 & (9,9) & 512 x 512 & 1 : 1 & 18 & 262,144 \\
D1 & (11, 7) & 2048 x 128 & 16 : 1 & 18 & 262,144 \\
D2 & (12, 6) & 4096 x 64 & 64 : 1 & 18 & 262,144 \\
D3 & (13, 5) & 8192 x 32 & 256 : 1 & 18 & 262,144 \\
\hline
\end{tabular}
\end{table}

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{discontinuities_by_perimeter_2d}
\caption{Size of the largest discontinuity by perimeter for 2D domains for Compact Hilbert Indices
from Hamilton and Rao-Chaplin~\cite{hamilton2008compact}.}
\label{fig:discontinuities-perimeter-2d}
\end{figure}

\begin{table}[htbp]
\centering
\label{tab:locality-metrics}
\begin{tabular}{llrrrr}
\toprule
Domain & Aspect & Hamilton $\mathrm{WL}_\infty$ & LC-CHI $\mathrm{WL}_\infty$ & Hamilton WBA & LC-CHI WBA \\
\midrule
$512 \times 512$   & 1:1   & 4.75 & 4.75  & 2.29 & 2.29 \\
$2048 \times 128$  & 16:1  & 442  & 4.75  & 435  & 2.29 \\
$4096 \times 64$   & 64:1  & 384  & 7.62  & 416  & 2.29 \\
$8192 \times 32$   & 256:1 & 512  & 26.2  & 528  & 2.33 \\
\bottomrule
\end{tabular}
\caption{Worst-case locality metrics for Hamilton-CHI and LC-BRGC across rectangular domains.
Key metrics: $\mathrm{WL}_\infty$ (Chebyshev locality), $\mathrm{WL}_2$ (Euclidean locality),
$\mathrm{WL}_1$ (Manhattan locality), WBA (bounding box area ratio), WBP (bounding box perimeter ratio).}
\end{table}


\begin{table}[htpb]
\centering
\label{tab:bounding-box-stats}
\begin{tabular}{llrrrrr}
\toprule
Domain & Curve & Block size $B$ & Mean $\frac{\text{bbox}}{B}$ & P95 $\frac{\text{bbox}}{B}$ & Max $\frac{\text{bbox}}{B}$ & Max $\frac{\text{peri}}{\sqrt{B}}$ \\
\midrule
512$\times$512 & Hamilton & 32 & 1 & 1 & 1 & 4.24 \\
 & LC-BRGC & 32 & 1 & 1 & 1 & 4.24 \\
 & Hamilton & 100 & 1.35 & 1.68 & 1.92 & 5.6 \\
 & LC-BRGC & 100 & 1.35 & 1.68 & 1.92 & 5.6 \\
 & Hamilton & 500 & 1.41 & 1.79 & 2.05 & 5.72 \\
 & LC-BRGC & 500 & 1.41 & 1.79 & 2.05 & 5.72 \\
 & Hamilton & 1024 & 1 & 1 & 1 & 4 \\
 & LC-BRGC & 1024 & 1 & 1 & 1 & 4 \\
\addlinespace
2048$\times$128 & Hamilton & 32 & 1 & 1 & 1 & 4.24 \\
 & LC-BRGC & 32 & 1 & 1 & 1 & 4.24 \\
 & Hamilton & 100 & 2.33 & 1.68 & 174.08 & 52.8 \\
 & LC-BRGC & 100 & 1.35 & 1.68 & 1.92 & 5.6 \\
 & Hamilton & 500 & 2.43 & 2.05 & 40.96 & 25.76 \\
 & LC-BRGC & 500 & 1.41 & 1.79 & 2.05 & 5.72 \\
 & Hamilton & 1024 & 1 & 1 & 1 & 4 \\
 & LC-BRGC & 1024 & 1 & 1 & 1 & 4 \\
\addlinespace
4096$\times$64 & Hamilton & 32 & 1 & 1 & 1 & 4.24 \\
 & LC-BRGC & 32 & 1 & 1 & 1 & 4.24 \\
 & Hamilton & 100 & 2.38 & 1.92 & 51.2 & 28.8 \\
 & LC-BRGC & 100 & 1.35 & 1.68 & 1.92 & 5.6 \\
 & Hamilton & 500 & 2.45 & 10.24 & 10.24 & 12.88 \\
 & LC-BRGC & 500 & 1.4 & 1.79 & 2.05 & 5.72 \\
 & Hamilton & 1024 & 1 & 1 & 1 & 4 \\
 & LC-BRGC & 1024 & 1 & 1 & 1 & 4 \\
\addlinespace
8192$\times$32 & Hamilton & 32 & 1 & 1 & 1 & 4.24 \\
 & LC-BRGC & 32 & 1 & 1 & 1 & 4.24 \\
 & Hamilton & 100 & 2.39 & 12.8 & 12.8 & 14.4 \\
 & LC-BRGC & 100 & 1.34 & 1.68 & 1.92 & 5.6 \\
 & Hamilton & 500 & 2.31 & 4.1 & 4.1 & 8.59 \\
 & LC-BRGC & 500 & 1.49 & 2.05 & 2.05 & 5.72 \\
 & Hamilton & 1024 & 1 & 1 & 1 & 4 \\
 & LC-BRGC & 1024 & 1 & 1 & 1 & 4 \\
\bottomrule
\end{tabular}
\caption{This is the “indexing application” table. It is more intuitive than 
WBA/WBP
WBA/WBP and more directly tied to how SFCs are used to build blocks (e.g., R-tree leaves). Haverkort motivates this style of evaluation by grouping consecutive points into blocks and measuring block bounding boxes. Computation: deterministic (no sampling) if you just partition the full curve into consecutive blocks of size B. Report both average and max because seam jumps tend to show up in the max/tails.}
\end{table}

\begin{table}[htpb]
\centering
\label{tab:range-query}
\begin{tabular}{lrrrrl}
\toprule
Curve & Query window & Mean clusters & P95 clusters & Max clusters & Method \\
\midrule
Hamilton & 4$\times$4 & 3.97 & 6 & 7 & exhaustive (249,673) \\
LC-BRGC & 4$\times$4 & 3.97 & 6 & 6 & exhaustive (249,673) \\
LC-Balanced & 4$\times$4 & 3.97 & 6 & 6 & exhaustive (249,673) \\
LC-Random & 4$\times$4 & 3.97 & 6 & 6 & exhaustive (249,673) \\
\addlinespace
Hamilton & 8$\times$8 & 7.92 & 13 & 14 & exhaustive (233,073) \\
LC-BRGC & 8$\times$8 & 7.94 & 13 & 14 & exhaustive (233,073) \\
LC-Balanced & 8$\times$8 & 7.94 & 13 & 14 & exhaustive (233,073) \\
LC-Random & 8$\times$8 & 7.94 & 13 & 14 & exhaustive (233,073) \\
\addlinespace
Hamilton & 16$\times$16 & 15.83 & 26 & 29 & exhaustive (199,969) \\
LC-BRGC & 16$\times$16 & 15.85 & 26 & 26 & exhaustive (199,969) \\
LC-Balanced & 16$\times$16 & 15.85 & 26 & 26 & exhaustive (199,969) \\
LC-Random & 16$\times$16 & 15.85 & 26 & 26 & exhaustive (199,969) \\
\addlinespace
Hamilton & 64$\times$4 & 33.64 & 53 & 55 & exhaustive (246,013) \\
LC-BRGC & 64$\times$4 & 33.56 & 54 & 59 & exhaustive (246,013) \\
LC-Balanced & 64$\times$4 & 33.56 & 54 & 59 & exhaustive (246,013) \\
LC-Random & 64$\times$4 & 33.56 & 54 & 59 & exhaustive (246,013) \\
\addlinespace
Hamilton & 4$\times$64 & 32.06 & 52 & 60 & exhaustive (4,093) \\
LC-BRGC & 4$\times$64 & 31.99 & 51 & 51 & exhaustive (4,093) \\
LC-Balanced & 4$\times$64 & 31.99 & 51 & 51 & exhaustive (4,093) \\
LC-Random & 4$\times$64 & 31.99 & 51 & 51 & exhaustive (4,093) \\
\addlinespace
Hamilton & 32$\times$32 & 31.47 & 50 & 54 & exhaustive (134,145) \\
LC-BRGC & 32$\times$32 & 31.57 & 50 & 53 & exhaustive (134,145) \\
LC-Balanced & 32$\times$32 & 31.57 & 50 & 53 & exhaustive (134,145) \\
LC-Random & 32$\times$32 & 31.57 & 50 & 53 & exhaustive (134,145) \\
\bottomrule
\end{tabular}
\caption{This is a range query, done by exhaustive enumeration. This counts the number of clusters within a query window, but it doesn't count the size
of the gaps, so it doesn't differentiate strongly between breaks in locality
and large adjacency skips~\cite{moon2001analysis}.}
\end{table}


\section{Conclusion}
We have a new algorithm to find Hilbert curves.

We have a new algorithm to generate a sequence of points ranked
by their Hilbert index.

We have a new algorithm to construct Hilbert curves of unequal side
lengths that are lattice-continuous.


\bibliographystyle{plain}
\bibliography{article}

\end{document}
