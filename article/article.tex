\documentclass{article}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{mathtools}      % For \coloneqq and other extensions
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{booktabs}       % For nice tables
\usepackage{array}
\usepackage{graphicx}
\usepackage{xspace}
\graphicspath{{figures/}}
\DeclareGraphicsExtensions{.pdf,.png,.jpg}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{enumitem}       % For customized lists
\usepackage{tikz}
\usetikzlibrary{arrows.meta, positioning}
\usepackage{geometry}
\geometry{
  left=0.75in,
  right=3in,
  top=0.5in,
  bottom=0.7in
}
\usepackage{setspace}
\onehalfspacing

% ============================================================================
% THEOREM ENVIRONMENTS
% ============================================================================
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{remark}[theorem]{Remark}

% ============================================================================
% CUSTOM COMMANDS FOR NOTATION
% ============================================================================
% Bit operations (matching Hamilton's notation)
\newcommand{\XOR}{\oplus\xspace}           % XOR: exclusive or
\newcommand{\AND}{\mathbin{\wedge}\xspace}            % AND
\newcommand{\OR}{\mathbin{\vee}\xspace}               % OR
\newcommand{\NOT}{\mathord{\sim}\xspace}              % NOT (bitwise complement)
\newcommand{\SHL}{\mathbin{\triangleleft}\xspace}     % Shift left
\newcommand{\SHR}{\mathbin{\triangleright}\xspace}    % Shift right
\newcommand{\ROTL}{\mathbin{\circlearrowleft}\xspace} % Rotate left
\newcommand{\ROTR}{\mathbin{\circlearrowright}\xspace}% Rotate right
\newcommand{\vplus}{\mathbin{\oplus}\xspace}   % plus
\newcommand{\vtimes}{\mathbin{\otimes}\xspace}

% Convenient shortcuts
\newcommand{\gc}{g\xspace}                  % Gray code function
\newcommand{\gcinv}{g^{-1}\xspace}          % Gray code inverse
\newcommand{\bitfn}{\mathrm{bit}\xspace}              % bit extraction function
\newcommand{\tsb}{\mathrm{tsb}\xspace}                % trailing set bits
\newcommand{\entry}{e\xspace}                % entry point function
\newcommand{\exitpt}{f\xspace}               % exit point function (f for "finish")
\newcommand{\dir}{d\xspace}                  % direction function
\newcommand{\gcr}{\mathrm{gcr}\xspace}                % Gray code rank
\newcommand{\order}{m_{\text{max}}\xspace}
\newcommand{\dk}{dk\xspace}
\newcommand{\embed}{\kappa\xspace}
\newcommand{\brgc}{BRGC\xspace}
% Sets
\newcommand{\Z}{\mathbb{Z}\xspace}                    % Integers
\newcommand{\N}{\mathbb{N}\xspace}                    % Natural numbers
\newcommand{\B}{\mathbb{B}\xspace}                    % Binary digits {0,1}

% Other
\newcommand{\encode}{\mathrm{encode}\xspace}
\newcommand{\decode}{\mathrm{decode}\xspace}


\title{Lattice-Continuous Compact Hilbert Indices via Affine Transformations on Hypercubes}
\author{Andrew Dolgert}
\date{\today}


\begin{document}
\maketitle
\begin{abstract}
Space-filling curves are fundamental to combinatorial optimization and multidimensional indexing.
Existing compact linearizations for unequal dimensions fail to preserve lattice continuity (adjacency), degrading locality.
We introduce a general construction using Gray codes and affine transformations in $\mathbb{F}_2^n$.
We prove this construction yields a lattice-continuous mapping for arbitrary dimension extents and provide an $O(mn)$ time algorithm.
\end{abstract}

\section{Introduction}

Space-filling curves are fundamental.

Recent interest in Hilbert curves: mesh refinement,
combinatorial optimization, multidimensional indexing. Use in AI.
They rely on continuity and search for better locality~\cite{franco2025pareto}.

Problems with unequal axes stem from presentation of gluing constraints.
Nice work in \cite{alber2000multidimensional,bradley2022behaviour}.

Locality depends on particular choice of Hilbert curve~\cite{haverkort2010locality}.
Would like to expand ability to use different Hilbert curves and expand locality
to unequal dimensions.

I don't love counting and staring at things when they are in $n$-dimensions.
Use $\mathbb{F}_2^n$ to stop staring.

\begin{itemize}
  \item Express gluing constaint in $\mathbb{F}_2^n$ for clarity.
  \item Give a dynamic program to construct valid orientation tables so that it is possible to generate new Hilbert curves quickly for any Gray code.
  \item Make unequal side lengths on better footing so they are lattice-continuous with less razzle-dazzle.
  \item Define a new mismatch state reduction that turns gluing into a constrained walk problem.
\end{itemize}

We show this problem is fundamentally about recursively stacking $k$-dimensional
hypercubes while keeping base edges aligned. By looking in $\mathbb{F}_2^n$
we reduce the orientation problem to a simple form.

\section{Preliminaries}
\subsection{Hyperrectangle}
Let dimensions $n\ge 1$ and extents $\mathbf{m}=(m_0,\ldots,m_{n-1})\in \mathbb{N}^n$ define a hyperrectangle.
$$
  P_n(\mathbf{m})=\prod_{j=0}^{n-1}\left\{0,1,\ldots,2^{m_j}-1\right\}
$$
The sum of extents is $M=\sum_{j=0}^{n-1}m_j$. If all $\mathbf{m}$ are equal,
we write, for instance, $P_k(2)$ for a $k$-dimensional lattice with $2^2$ points
in each dimension.

\subsection{Lattice-continuous Hilbert Curve}

\begin{definition}[Lattice-continuous index]
  A bijection $H: P_n(\mathbf{m})\rightarrow \{0,1,\ldots,2^M-1\}$
  between a \emph{point} in $P(\mathbf{m})$ and an \emph{index} in $\mathbb{Z}$
  is \emph{lattice-continuous} if $||H^{-1}(t)-H^{-1}(t+1)||_1$
  for all $t\in\{0,1,\ldots,2^M-2\}$.
\end{definition}

\begin{definition}[Hilbert curve]
A Hilbert curve or order $m$ is a lattice-continuous index on $P_n(\mathbf{m})$
with $m=\max(\mathbf{m})$ and boundary conditions
$H(\mathbf{0})=0$ and $H((2^{m_j}-1)\mathbf{e}_j)=2^M-1$ for some axis $j$.
\end{definition}

\subsection{Binary Hypercube}
Recursive algorithms for Hilbert curves partition each level using
binary hypercubes.

For $k\ge 1$, let $V_k=\mathbb{F}_2^k=\{0,1\}^k$ and identify it with the vertex
set of the $k$-dimensional hypercube $Q_k$. This space is equipped with
addition $\vplus$ and multiplication $\vtimes$ which correspond to
an XOR and AND operation on bit representations.

Vertices $u,v\in V_k$ are adjacent if $u\oplus v \in \{\mathbf{e}_0,\ldots,\mathbf{e}_{k-1}\}$ where $\mathbf{e}_j$ is a unit vector along the $j$ axis.


\subsection{Affine automorphisms and orientations}

A map $A : V_k\rightarrow V_k$ is an \emph{affine automorphism} of $Q_k$
if it is of the form $A(x)=Px\vplus a$ where $P$ is a coordinate permutation
matrix over $\mathbb{F}_2^k$ and $a\in V_k$. Affine automorphisms preserve adjacency.

Our main concern, however, will be the orientation of directed edges, where
a directed edge is a pair of position and direction, $(e\in V_k,d\in \{0,\ldots,k\})$.

\emph{Cyclic affine transformations} consist of a cyclic rotation $\rho$ and
a translation $e$.
$$
T_{e,d}(y)=\rho^d y \vplus e\qquad d\in \mathbb{Z}, e\in V_k
$$
Together, $(e,d)$ form the semi-direct product of the permutation group and
translation group.
These can transform any directed edge in $Q_k$ to any other directed edge but
do not include general permuations. The number of affine automorphisms
is $2^k\prod_{i=0}^{k-1}(2^k-2^i)$ versus the cyclic affine maps which number
$k2^k$~\cite{lidl1997finite}. For $k=3$, there are 1344~affine automorphisms and 24~cyclic affine maps.

Note that this definition of $T_{e,d}$ differs from that of Hamilton and
Rao-Chaplin becuase it rotates by $d$ rather than $d+1$.

\subsection{Binary Gray Codes}\label{sec:binary-gray}

A binary Gray code is a Hamiltonian path on $Q_k$ for $k\ge 1$. 
A Gray code as a bijection
$$
  G_k : \{0,1,\ldots,2^k-1\}\rightarrow V_k \quad R_k : V_k\rightarrow \{0,1,\ldots,2^k-1\}
$$
with $R_k=G_k^{-1}$ the rank of a point in $Q_k$. In $V_k$, adjacent Gray codes
define a unique axis
$$
  G_k(w) + G_k(w+1)=\mathbf{e}_{\sigma_k(w)}.
$$

The Hilbert algorithm will use the Gray code rank to determine the visiting
order within a hypercube. Of particular interest are the rank~$0$ and rank~$2^k-1$
elements of the hypercube because they determine adjacency as shown in Sec.~XXX.

There are many Gray codes but the rank~$2^k-1$ exit point will always be adjacent
to the rank~$0$ entry point according to Alber and Niedermeier~\cite{alber2000multidimensional}. It will be convenient to assume a \emph{base frame} defined
by an origin and a primary axis.
$$
  G_k(0)=\mathbf{0} \quad G_k(2^k-1)=\mathbf{e}_0.
$$

The best-known Gray code, used by Butz and Hamilton among others~\cite{butz2006alternative,hamilton2006compact}, is the \emph{binary-reflected Gray code} (\brgc). This Gray code has closed-form expressions for $G_k$ and $R_k$ and is
\emph{linear} in $V_k$.
It's first element is at the origin, but its last element is in $\mathbf{e}_{k-1}$,
so we will consider it rotated by one, using $T_{\mathbf{0},-1}$, to meet the boundary conditions.
This rotation of the \brgc is a common, if implicit, assumption that can show up as a $+1$ in
initial conditions and later transformations~\cite{hamilton2008compact}.


\subsection{Bit plane decomposition}

We decompose the space $P(\mathbf{m})$ into levels $s\in \{m, m-1,\ldots,1\}$.
The level-$s$ bit-plane vector is the $(s-1)$-th bit of each coordinate of the
point in $P$.
The space of each level is $V_k$ where $k = |\{j : m_j \ge s\}| \le n$.
It is in this space, which defines how we recursively decompose the domain
of a Hilbert curve, that we rank Gray codes and orient child levels with affine
transformations.


\section{Hilbert curve construction with affine transforms}
The key is connecting orientation and adjacency.

We could do this with point-free language, but would you believe it?

A lattice-continuous Hilbert curve relies on continuity across decomposition
levels.

Claim: You can construct a Hilbert curve recursively from a Hilbert curve
and a Gray code equipped with a set of directed edges in $V_k$.

\subsection{Explicit $P_k(2)$ Construction}
Consider a point domain of order $m=2$. Identify the level~2 decomposition
with a high bit $h\in V_2$ and the level~1 decomposition with a low bit
$\ell\in V_2$. We can make a map from $(V_2\times V_2) \rightarrow P_k(2)$.
$$
x = 2h +\ell \quad h,\ell \in V_k
$$
Rank the high bits with a Gray code so that the sequence
$h_w=R_k(w)$ for $w\in\{0,\ldots,2^k\}$
traverses all of the $2^k$ cubes in $P_k(2)$. Let $d_w\coloneq \sigma_k(w)$
so that $h_{w+1}=h_w\vplus \mathbf{e}_{d_w}$.

There will be an entry and exit vertex for the $2^k$ points within the child domain.
As described in Sec.~\ref{sec:binary-gray}, the exit corner is a unit step $a_w$ from
the entrance corner. In the context of $P_k(2)$, we consider them in coordinate space.
$$
  \ell_w^{\text{out}} \coloneq \ell_w^{\text{in}}\vplus \mathbf{e}_{a_w}
$$

\subsection{Gluing Constraint}

Crossing from cube \(h_w\) to cube \(h_{w+1}=h_w\vplus\mathbf{e}_{d_w}\) happens across the shared face in axis \(d_w\).
In \((h,\ell)\)-coordinates, the unique lattice adjacency across that face flips both the high and low bits in axis \(d_w\).
Therefore, lattice continuity across the seam forces
\begin{equation}\label{eq:seam}
(h_{w+1},\ell^{\mathrm{in}}_{w+1}) = (h_w\vplus\mathbf{e}_{d_w},\;\ell^{\mathrm{out}}_w\vplus\mathbf{e}_{d_w}).
\end{equation}
Equivalently, in low-bit coordinates:
\begin{equation}\label{eq:glue-low}
\ell^{\mathrm{in}}_{w+1} = \ell^{\mathrm{in}}_w \vplus \mathbf{e}_{a_w} \vplus \mathbf{e}_{d_w}.
\end{equation}
The direction $d_w$ is given by the chosen Gray code, so a lattice-continuous
Hilbert curve is defined by a family of cyclic affine transformations.
For what $(e,d)$ is it true that the gluing constraint holds?
\begin{equation}
  T_{e,d}(G_k(0))=\ell_w^{\text{in}}\quad T_{e,d}(G_k(2^k-1))=\ell_w^{\text{in}} + a_w
\end{equation}
We can think of this family as being parametrized either by the Gray code within
the parent or by the point in the parent corresponding to the child hypercube.
\begin{equation}
  \mu_k(w) \coloneq (e,d)=(l_w^{in}, a_w)\quad \text{or }\mu_k(h) = (l_h^{in}, a_h)
\end{equation}
When these are known, we can rewrite our original map using the coordinates
of the child.
\begin{equation}
  x = 2h + T_{\mu(w)} \ell_w \quad h\in V_k, \ell_w\in V'_k \label{eqn:parent-child-coords}
\end{equation}
Here we the space for the child as $V'_k$. For this construction, the Hilbert
index is
\begin{equation}
  H(x)=2^kR(h) + R(\ell)
\end{equation}

Note that the adjacency relation depends on $d_w$ for the parent but does not
depend on the shape of the Gray code used by the child.

\subsection{Induction}

We just demonstrated a concrete construction of a two-level curve.
Let's show that the same transforms from the two-level construction
apply to descent from level $s$ to level $s-1$.

Again we define a high and low, but the low is in $P_k(s)$.
\begin{equation}
x = 2^sh + \ell\quad h\in V_k, \ell\in P_k(s), 
\end{equation}
Treat $\l_w^{\text{in}}$ as a \emph{corner label} not the full $\ell\in P_k(s)$.

Lift the transforms $T_{e,d}$ to $P_k(s)$ by writing a coordinate in $P_k(s)$
as a sum of bit planes.
\begin{equation}
  \ell = \sum_{j=0}^{s-1}2^jb_j(\ell)\quad b_j(x)\in V_k
\end{equation}
Now define a lifted transform.
\begin{equation}
  \tilde{T}_{e,d}(x) \coloneq \sum_{j=0}^{s-1}2^j T_{e,d}(b_s(x))
\end{equation}
Because $\XOR$ with $e$ applied to every bit-plane complements the entire
$s$-bit word when $e_i=1$, the same map can be written coordinatewise.
\begin{equation}
  \left(\tilde{T}_{e,d}(x\right)_i = \left(x_{\rho^d(i)}\right)\vplus \left(e_i(2^s-1)\right)
\end{equation}
That is, for our boundary conditions, the translation in $T_{e,d}$ determines
whether the axis is flipped for $P_k(s)$.
\begin{equation}
  \left(\tilde{T}_{e,d}(x\right)_i = \begin{cases}
  x_{\rho^d(i)}, & \mathbf{e}_i=0 \\
  (2^j-1)-x_{\rho^d(i)}, & \mathbf{e}_i=1
  \end{cases}
\end{equation}
As with $T_{e,d}$, $\tilde{T}_{e,d}$ is a bijection, so it preserves
lattice adjacency within $P_k(s)$.

The gluing condition, Eq.~\ref{eq:glue-low}, remains true in this context
if we see it as a corner condition, so $\ell_w^{\text{in}}$ is a corner label.

The Hilbert curve becomes
\begin{equation}
  H_{s+1}(2^{ks}w + c)\coloneq 2^s h_w + \tau_w^{s}(H_j(s))
\end{equation}

Prove bijection: The sets $2^sh_w+P_k(s)$ are disjoint and cover $P_k(j+1)$
(standard dyadic partition). On each such set, $\tau_w^{s}\odot H_j$ is a bijection Since
$H_j$ is and $\tau_w^{s}$ is a bijection. So the concatenation visits every
point exactly once.

Seam adjacency: This reduces to the $\mathbb{F}_2^k$ gluing constraint.
The entry and exit points of consecutive subcubes are known by construction.
\begin{equation}
\begin{aligned}
X_w^{\text{out}} & = H_{s+1}((w+1)2^{ks}-1) \\
X_{w+1}^{\text{in}} & = H_{s+1}((w+1)2^{ks}) \\
\end{aligned}
\end{equation}

We can trace adjacency as before. When leaving one child hypercube to traverse
to another, one bit flips in the high bit, and one bit flips in the low bit.
Here, the bit flips in the low bit \emph{corner}, so it changes by $\vplus$
with $e_{d_w}$, in accordance with the seam constraint.

Geometrically: Stepping to the neighboring subcube along axis $d_w$ changes the
high contribution by $\pm 2^s \mathbf{e}_{d_w}$, and the low corner flips between
the two opposite faces (coordinate $0 \leftrightarrow 2^s-1$), changing the low
contribution by $\mp(2^s-1)\mathbf{e}_{d_w}$. Those two changes always sum to
$\pm 1e_{d_w}$, that is a distance~1 move.

\section{Directed Edges for any Gray Code}

Were we to know the set of transforms for a particular Gray code,
then we would have a Hilbert curve. Where do we get the transforms?
The most popular method is to construct a graph for the $P_k(2)$ case
and solve for all paths consistent with the Gray code's Hamiltonian path
and Hilbert boundary conditions. These methods work well, but there are strong
geometric constraints from subdivision of the space. These constraints suggest
there might be more structure in the problem, such as the interaction between
the high-bit coordinate and the low-bit coordinate.

\subsection{Mismatch}\label{sec:mismatch}

By construction the Gray code fixes the \emph{parent} walk through the $2^k$ child cubes:
it gives the sequence of high-bit vertices $h_w$ and, for each step, the unique axis
$d_w$ with $h_{w+1}=h_w\vplus \mathbf{e}_{d_w}$.
What remains is to choose, in each child cube, an \emph{orientation} of the lower-level curve:
an entry corner $\ell_w^{\mathrm{in}}\in V_k$ and an exit direction $a_w$ so that consecutive
children glue together across a single lattice edge.
Equation~\eqref{eq:glue-low} expresses exactly that seam constraint.

When we first tried to reason about \eqref{eq:glue-low} directly, the geometry was hard to
see because the equation mixes two coordinate frames.
The term $h_w$ is a global description (which subcube we are in),
while $\ell_w^{\mathrm{in}}$ is a local description (which corner of that subcube we use).
Across a seam, however, the lattice does not care about these two pieces separately:
it only cares about their \emph{relative} alignment.
This suggests introducing a state that measures how the local entry corner sits relative to the
position of its parent cube.

\begin{definition}[Mismatch state]
For each child index $w$, define the \emph{mismatch} \(s_w\in V_k\) by
\begin{equation}\label{eq:mismatch}
  s_w \coloneqq h_w \vplus \ell_w^{\mathrm{in}}.
\end{equation}
\end{definition}

\paragraph{Geometric meaning.}
In the two-level model $P_k(2)$, each coordinate is
$x_i = 2(h_w)_i + (\ell_w^{\mathrm{in}})_i \in \{0,1,2,3\}$.
A short check shows
\[
(s_w)_i = (h_w)_i \vplus (\ell_w^{\mathrm{in}})_i
=
\begin{cases}
0, & x_i\in\{0,3\}\quad\text{(outer faces)},\\
1, & x_i\in\{1,2\}\quad\text{(the two layers adjacent to the internal face)}.
\end{cases}
\]
Thus $s_w$ is a $k$-bit \emph{face code}: the $i$-th bit is $1$ precisely when the entry corner of
child cube $w$ lies on the interior face that is shared between the two halves in axis $i$.

The payoff is that the seam constraint becomes a constraint \emph{only} on this face code.

\begin{lemma}[Mismatch-state form]\label{lem:mismatch}
Let $s_w$ be defined by \eqref{eq:mismatch}. Then the low-bit gluing constraint
\eqref{eq:glue-low} is equivalent to the pair of constraints
\begin{align}
 s_{w+1} &= s_w \vplus \mathbf{e}_{a_w}, \label{eq:s-walk}\\
 (s_{w+1})_{d_w} &= 1. \label{eq:s-face}
\end{align}
\end{lemma}

\begin{proof}
For the walk constraint \eqref{eq:s-walk}, use the Gray-code step
$h_{w+1}=h_w\vplus\mathbf{e}_{d_w}$ and the gluing rule \eqref{eq:glue-low}:
\[
\begin{aligned}
 s_{w+1}
 &= h_{w+1}\vplus \ell^{\mathrm{in}}_{w+1}
 = (h_w\vplus\mathbf{e}_{d_w}) \vplus (\ell^{\mathrm{in}}_w\vplus\mathbf{e}_{a_w}\vplus\mathbf{e}_{d_w})
 = (h_w\vplus\ell^{\mathrm{in}}_w)\vplus\mathbf{e}_{a_w}
 = s_w\vplus\mathbf{e}_{a_w}.
\end{aligned}
\]
For the face constraint \eqref{eq:s-face}, recall from \eqref{eq:seam} that the seam vertex
\((h_{w+1},\ell^{\mathrm{in}}_{w+1})\) lies on the shared face orthogonal to axis $d_w$.
In the two-bit decomposition along that axis, being on the shared face means the low bit is the complement of the high bit:
\((\ell^{\mathrm{in}}_{w+1})_{d_w} = 1-(h_{w+1})_{d_w}\).
Over $\mathbb{F}_2$ this is \((\ell^{\mathrm{in}}_{w+1})_{d_w} \vplus (h_{w+1})_{d_w}=1\), i.e.
\((s_{w+1})_{d_w}=1\).
\end{proof}

Lemma~\ref{lem:mismatch} turns the seam problem into a constrained walk on the hypercube $Q_k$.
At step $w$, the Gray code tells us which axis $d_w$ the \emph{parent} moves along.
We must choose the next mismatch state $s_{w+1}$ adjacent to $s_w$ (one bit flip), but we are only allowed to land in the half-cube where bit $d_w$ equals $1$.
Once a mismatch walk $(s_w)$ is fixed, the original geometric data are recovered by
\[
\ell_w^{\mathrm{in}} = h_w\vplus s_w,
\qquad
a_w = \text{the unique axis with } s_{w+1}=s_w\vplus \mathbf{e}_{a_w},
\]
and the corresponding orientations are $T_{\ell_w^{\mathrm{in}},a_w}$.

\subsection{Existence}\label{sec:existence}

The mismatch formulation makes the existence question transparent:
given a Gray code (hence a sequence of step axes $d_w$), does there always exist a mismatch walk satisfying \eqref{eq:s-walk}--\eqref{eq:s-face}?
Yes; a valid walk can be constructed greedily.

\begin{proposition}[A mismatch walk always exists]\label{prop:existence}
Let $(h_w)_{w=0}^{2^k-1}$ be any Gray code on $V_k$, and let $d_w$ be its step axis defined by
$h_{w+1}=h_w\vplus\mathbf{e}_{d_w}$.
There exists a sequence $(s_w)_{w=0}^{2^k-1}$ in $V_k$ with $s_0=\mathbf{0}$ satisfying
\eqref{eq:s-walk}--\eqref{eq:s-face}, and hence there exists at least one choice of entry corners
$\ell_w^{\mathrm{in}}$ and exit directions $a_w$ that satisfies the gluing constraint \eqref{eq:glue-low}.
\end{proposition}

\begin{proof}
Set $s_0=\mathbf{0}$.
For each $w=0,\ldots,2^k-2$, let $d=d_w$.

If $(s_w)_d=0$, we are \emph{forced} to flip bit $d$: set $a_w=d$ and $s_{w+1}=s_w\vplus\mathbf{e}_d$.
Then $(s_{w+1})_d=1$.

If $(s_w)_d=1$, we may flip any other bit and keep bit $d$ equal to $1$.
For $k\ge 2$, choose a fixed rule such as $a_w=(d+1)\bmod k$ (so $a_w\neq d$) and set
$s_{w+1}=s_w\vplus\mathbf{e}_{a_w}$.
For $k=1$ this case never occurs because there is only one step.

In either case $s_{w+1}$ is adjacent to $s_w$ and satisfies \eqref{eq:s-face}.
Repeating for all $w$ constructs a valid mismatch walk.
\end{proof}

\subsection{Unequal Side Lengths}

If the desired lattice has unequal extents, then the highest levels will
have fewer dimensions and lower levels more dimensions. We can
rewrite Eq.~\ref{eqn:parent-child-coords} by introducing an \emph{embedding}
of the smaller dimension $k_s$ into a larger dimension $k_{s-1}$. Given the
embedding, we will need to determine a new cyclic affine transform.
\begin{equation}
  x = 2\kappa h + T_{e,d}\ell
\end{equation}
The gluing constraint is also affected by the embedding. If we presume that
we have already determined a family of curves $\mu$ for dimension $k_s$, the
the gluing constraint, Eq.~\ref{eq:glue-low}, holds. The embedding distributes
across the terms in the gluing constraint, here applied to the known solution 
for entry and direction in the lower dimension.
\begin{equation}\label{eq:glue-low-embed}
\kappa\ell^{\mathrm{in}}_{w+1} = (\kappa\ell^{\mathrm{in}}_w) \vplus (\kappa\mathbf{e}_{a_w}) \vplus (\kappa\mathbf{e}_{d_w}).
\end{equation}
The updated curve is directly embedded.
\begin{equation}
  \ell_w^{\prime\text{in}} = \kappa \ell_w^{\text{in}} \quad \mathbf{e}'_{a_w}=\kappa \mathbf{e}_{a_w}
\end{equation}
In this context, the affine transformation, given a Gray code and a known curve
for the case of equal dimensions, becomes
\begin{equation}
  T_{e,d}(G_k(0))=\kappa\ell_w^{\text{in}}\quad T_{e,d}(G_k(2^k-1))=\kappa\ell_w^{\text{in}} + \kappa a_w
\end{equation}

We can make a convenient assumption if we order axes from largest to smallest.
Then the $0$-axis remains the same, and this is the base frame for the Gray curve.
While $T_{e,d}$ in $V_{k_s}$ differs from $T_{e,d}$ in $V_{k_{s-1}}$, the only
difference will be the number of axes in the cyclic affine transformation.

\section{Automated Generation of Curves}

\paragraph{Example: \brgc and closed-form families.}
The point of the mismatch state is not just existence, but \emph{structure}.
For the binary-reflected Gray code,
\[
G(w) = w \vplus (w\SHR 1)\in V_k,
\]
the step axis is the ruler function
\[
G(w+1)=G(w)\vplus \mathbf{e}_{\operatorname{ctz}(w+1)},
\qquad
\operatorname{ctz}(t)=\text{the number of trailing zeros in the binary expansion of }t.
\]
In the rotated base frame used in this paper (so that the Gray code exits at $\mathbf{e}_0$ rather than $\mathbf{e}_{k-1}$), the step axis is shifted by one:
\[
d_w = \big(\operatorname{ctz}(w+1)+1\big)\bmod k.
\]
Lemma~\ref{lem:mismatch} then says that at time $t=w+1$ we must have
\((s_t)_{(\operatorname{ctz}(t)+1)\bmod k}=1\),
but we are otherwise free to choose any adjacent move.
That ``one forced bit per step'' viewpoint makes it easy to see why there are many valid \brgc-based Hilbert rules.

Define the ``hub'' bit $\mathrm{hub}=1$ (for $k\ge 2$) and, for even $t>0$, define
\[
r(t) \coloneqq \big(\operatorname{ctz}(t)+1\big)\bmod k.
\]
Even indices force bit $r(t)$ to be $1$; odd indices force the hub bit to be $1$.
Keeping the hub bit fixed is a convenient way to satisfy all odd-step constraints, and it confines the mismatch walk to the $(k{-}1)$-dimensional slice $\{s : s_{\mathrm{hub}}=1\}$.

\emph{Hamilton's choice} is the minimal way to satisfy the even-step constraints:
\begin{equation}\label{eq:hamilton-mismatch}
s_0=\mathbf{0},\qquad
s_w=
\begin{cases}
\mathbf{e}_{\mathrm{hub}}, & w\ \text{odd},\\[2pt]
\mathbf{e}_{\mathrm{hub}} \vplus \mathbf{e}_{r(w)}, & w\ \text{even},\ w>0.
\end{cases}
\end{equation}
From $s_w$ we recover Hamilton's closed forms for the entry corner and child exit direction:
\[
\ell_w^{\mathrm{in}} = h_w\vplus s_w,
\qquad
a_w = \text{the unique bit index of }(s_w\vplus s_{w+1}).
\]
In particular, writing $w^- \coloneqq (w-1)\AND \NOT 1$ (``clear the least-significant bit''), one finds
\[
\ell_0^{\mathrm{in}}=\mathbf{0},
\qquad
\ell_w^{\mathrm{in}} = h_{w^-}\quad (w>0),
\]
which is Hamilton's \texttt{child\_entry}, and the exit-axis function admits the familiar trailing-ones form:
\[
a_w =
\begin{cases}
\mathrm{hub}, & w=0,\\
\big(\tsb(w)+\mathrm{hub}\big)\bmod k, & w\ \text{odd},\\
\big(\tsb(w-1)+\mathrm{hub}\big)\bmod k, & w\ \text{even},\ w>0,
\end{cases}
\]
where $\tsb(x)$ is the number of trailing 1-bits of $x$.

The mismatch constraints also make it easy to write down \emph{other} closed forms.
For example, keep the even steps exactly as in \eqref{eq:hamilton-mismatch} but change what happens at odd indices:

\smallskip
\noindent\textbf{Alt~A (``look both ways'').}
Set $s_0=\mathbf{0}$ and $s_1=s_{2^k-1}=\mathbf{e}_{\mathrm{hub}}$.
For even $w>0$ set $s_w=\mathbf{e}_{\mathrm{hub}}\vplus \mathbf{e}_{r(w)}$ as before, but for interior odd $w$ set
\[
s_w = \mathbf{e}_{\mathrm{hub}}\vplus \mathbf{e}_{r(w-1)}\vplus \mathbf{e}_{r(w+1)}.
\]

\smallskip
\noindent\textbf{Alt~B (alternate free choices).}
Use the same even-step rule, and for odd $w\notin\{1,2^k-1\}$ set
\[
s_w =
\begin{cases}
\mathbf{e}_{\mathrm{hub}}, & w\equiv 1\pmod 4,\\
\mathbf{e}_{\mathrm{hub}}\vplus \mathbf{e}_{r(w-1)}\vplus \mathbf{e}_{r(w+1)}, & w\equiv 3\pmod 4.
\end{cases}
\]

Both alternatives satisfy \eqref{eq:s-walk}--\eqref{eq:s-face}, hence both yield valid (but different) closed-form rules
for $(\ell_w^{\mathrm{in}},a_w)$ via $\ell_w^{\mathrm{in}}=h_w\vplus s_w$ and $a_w$ from $s_w\vplus s_{w+1}$.
For $k=3$, the resulting mismatch sequences are visibly different:
\[
\begin{array}{rcl}
\text{Hamilton:} && 000,\ 010,\ 110,\ 010,\ 011,\ 010,\ 110,\ 010,\\
\text{Alt A:}    && 000,\ 010,\ 110,\ 111,\ 011,\ 111,\ 110,\ 010,\\
\text{Alt B:}    && 000,\ 010,\ 110,\ 111,\ 011,\ 010,\ 110,\ 010.
\end{array}
\]
These are three distinct families of directed-edge tables for the same high-bit \brgc skeleton.

\subsection{Bradley's Bubble and Ring}

Bradley and Jahn defined families Hilbert curves for the \brgc by choosing
affine curves with regular structured~\cite{bradley2022behaviour}.
They called these the Bubble and Ring.
These are rules that compute a choice of entry and axis direction for a child
hypercube given the last choice of entry and axis direction, so they
return $\mu(w, k, \mu(w-1, k))$. They are neither
a closed-form solution that gives $\mu(w,k)$ nor a table-driven solution, but
they will be valuable when we discuss a common algorithm for Hilbert curves,
the generation of all points ranked by Hilbert index. In this context of streaming
point values, the ability to generate curves on the fly obviates excess memory
access.

We can also apply the spirit of the Bubble and Ring to produce regular sets
of affine transforms for \emph{any} Gray code, not just the \brgc.

We know from Sec.~XXX that the mismatch coordinate dictates the next transform
if $(s_w)_{d_w}=0$. In all other cases, any $a_w\ne d_w$ works.

Define an axis-order list $D_w^{+}$ as a list of axis indices $[0,1,\dots,k-1]$
in a permutation order. Given $d_w$ and $s_w$, 1. update the axis order using Bubble
or Ring. 2. Choose the mismatch-step axis $a_w$ by
\begin{equation}
a_w\coloneq\begin{cases}
d_w, & \text{if } (s_w)_{d_w}=0\quad\text{forced} \\
D_{w}^{+}[1], & \text{if } (s_w)_{d_w}=1 \quad\text{free to pick}
\end{cases}
\end{equation}
3. $s_w+1=s_w\vplus e_{a_w}$.

The updates reorder, represented here with a concatenation operator $||$.
\begin{equation}
D_{w}^{+} = \text{Bubble}(D_w,d_w)\coloneq [d_w] || [x\in D_w : x\ne d_w]
\end{equation}
\begin{equation}
D_{w}^{+} = \text{Ring}(D_w,d_w)\coloneq D_w[j:] || D_w[:j]
\end{equation}
For Ring, if you fix the cyclic order, then the state can be the index of the
next value in that order.

There is some discrepancy here with the original paper's definitions because
the transformations aren't restricted to rotations.


\subsection{dynamic program}
Yup, it's running, and it's wicked fast. Just gotta write it here.

Given that we have a concise description of which paths are allowed through
$P_k(2)$, we can create an algorithm to generate them efficiently.


\section{Construction}


\subsection{Encode and decode for equal side lengths}

This is a recursive algorithm that starts at the level $s=m$ and progresses
to level $s=1$. The state at each level is defined by the
current bit plane and the transform $T_{e_s,d_s}$.

Start with the identity as the transform. Extract the bit plane $b_s$ for level $s$ from
input coordinates $p$. Transform them with $b'_s=T^{-1}_{e_s,d_s}(b_s)$. Rank them with $w_s=R(b'_s)$. Scatter that rank $w$ into the Hilbert index at $\rho^{m*(s-1)}w$.
Update the transform for the next level down so it conforms to the curve,
$$
T_{e_{s-1},d_{s-1}}=T_{e_w,d_w}T_{e_s,d_s}
$$
This is equivalent to $e_{s-1}=\rho^d e_s + e_w$ and $d_{s-1}=d_s + d_w$.

Decoding is similar. The recursion and state are the same. At each level,
extract from the Hilbert index the rank, $w_s$ for this level. Find the coordinate
with $b'_s=G(w_s)$. Convert that to the local coordinates with $T_{e_w,d_w}$,
and scatter the resulting coordinate in $V_k$ into the $s-1$ bit of the
point coordinates. Finally, update the transform state for the level below.

\subsection{Unequal high + low}

What happens when we have unequal side lengths? In this recursive description,
the higher levels will have fewer dimensions, as few as $k=1$. Before, we
presented a two-level model for $P_k(2)$. Imagine now we have $k$ dimensions
at level $s$ and $k-dk$ levels at dimension $s-1$. The low bits will be
$\ell\in V_{k+dk}$.

We can choose an embedding for the high bits, $\kappa_s : V_k \rightarrow V_{k+dk}$.
If we previously had a two-level curve, we now act on both sides of Eq.~XXX
with the embedding.
$$
\kappa_s x = 2\kappa_s h + \kappa_s T_{e_w,d_w}(\kappa^{-1}_s\ell) \quad h\in V_k, \ell\in V'_{k+dk}
$$
Here, $\kappa_s^{-1}$ is the left-inverse of $\kappa_s$. In order to match
boundary conditions, we require that $\kappa_s^{-1}\mathbf{0}_{k+dk}=\mathbf{0}_{k}$
and that $\kappa_s^{-1}\mathbf{e}_{0,k+dk}=\mathbf{e}_{0,k}$. This may require
rotation of axes.

Because of the embedding, the boundary conditions remain associated with
the highest level of the decomposition, even if the origin of the coordinate
system changes as levels descend.

\subsection{Unequal encode and decode}

You can imagine the case where the extents are $(2,3,2)$ so that at level
$s=2$ the origin at the lower level is in $e_0$ in $V_3$ whereas the origin
at the parent level naturally at $e_1$ in $V_3$.

There is a convenient solution to the bookkeeping. At the start of the
calculation, order axes so that $m_0<m_1<\cdots m_{n-1}$. This way the
embedding won't shift the boundary conditions at $\mathbf{0}$ and $\mathbf{e}_0$
because the axis at 0 stays active.

If you want to use an arbitrary embedding, you can do it.

This does, however, mean that the algorithm for unequal side lengths has a 
different embedding operator. Whereas before for equal sides the operator
was $T^k_{e_w,d_w}$ it is now $T^{k+ds}_{e_w,d_w}$ which is the same offset now
embedded in the larger space and the same amount of circular rotation but embedded
into the larger space.

There is otherwise no change to the algorithm.

Algorithm for point-to-index (not a surprise).
\begin{algorithm}
\caption{Point to Index}
\label{alg:point-to-index}
\begin{algorithmic}[1]
\Require Point $p$
\Ensure Point $p\in P_n$.

\State $(e, d) \gets (0,0)$

\For{$s = m_{\max}$ \textbf{downto} $1$}
    \If{$s < m_{\max}$}
        \State $(e_0, d_0)\gets \mu(w, k)$ \Comment{Table lookup of Hilbert rule.}
        \State $(e, d)\gets (S_{e,d}(e_0, d_0), d+d_0\mod k)$ \Comment{Compose transforms}
    \EndIf
    \State $i=\text{gather\_plane}(p, k, s)$ \Comment{Extract level from dims}
    \State $w = G^{-1}(S_{e,d}^{-1}(i, k))$ \Comment{Transform to rank}
    \State $h = S_{k,w}(h)$ \Comment{Include in index}
\EndFor
\Return $h$
\end{algorithmic}
\end{algorithm}

Algorithm for index-to-point (not a surprise).
\begin{algorithm}
\caption{Index to Point}
\label{alg:index-to-point}
\begin{algorithmic}[1]
\Require Index $h$
\Ensure Index $h\in [0,\ldots,2^{mn}-1]$.

\State $(e, d) \gets (0,0)$

\For{$s = m_{\max}$ \textbf{downto} $1$}
    \If{$s < m_{\max}$}
        \State $(e_0, d_0)\gets \mu(w, k)$ \Comment{Table lookup of Hilbert rule.}
        \State $(e, d)\gets (S_{e,d}(e_0, d_0), d+d_0\mod k)$ \Comment{Compose transforms}
    \EndIf
    \State $i=\text{gather\_plane}(p, k, s)$ \Comment{Extract level from dims}
    \State $w = G^{-1}(S_{e,d}^{-1}(i, k))$ \Comment{Transform to rank}
    \State $h = S_{k,w}(h)$ \Comment{Include in index}
\EndFor
\Return $h$
\end{algorithmic}
\end{algorithm}

Algorithm for next-index, which can generate a sequence of points in $O(1)$ time by recalculating transforms only as needed. (Maybe this is nice.
Has anybody done this before?)
\begin{algorithm}
\caption{Neighbor Index with Cached State}
\label{alg:neighbor}
\begin{algorithmic}[1]
\Require Cached decode state for $h_0 \to p_0$: entry states $(e^{(s)}, d^{(s)})$, digits $w^{(s)}$, active axes $A_s$, point $p_0$
\Require Neighbor axis $j$ and direction $\delta \in \{-1, +1\}$
\Ensure Hilbert index $h_1 = H(p_0 + \delta \cdot \epsilon_j)$, or $\bot$ if out of bounds

\State $p'_j \gets p_{0,j} + \delta$
\If{$p'_j < 0$ or $p'_j \geq 2^{m_j}$}
    \Return $\bot$ \Comment{Out of bounds}
\EndIf

\State $\textit{changed} \gets p_{0,j} \XOR p'_j$ \Comment{Which bits differ}
\State $s^* \gets \max\{s : \text{bit } (s{-}1) \text{ of } \textit{changed} \text{ is set and } j \in A_s\}$

\State $h_1 \gets 0$
\For{$s = m_{\max}$ \textbf{downto} $s^* + 1$} \Comment{Copy unchanged high digits}
    \State $h_1 \gets (h_1 \SHL k_s) \OR w^{(s)}$
\EndFor

\State $(e, d) \gets (e^{(s^*)}, d^{(s^*)})$ \Comment{Restore cached entry state}

\For{$s = s^*$ \textbf{downto} $1$} \Comment{Recompute from $s^*$ down}
    \State $\ell \gets 0$
    \For{$t = 0$ \textbf{to} $k_s - 1$} \Comment{Pack level-$s$ bits of neighbor}
        \State $a \gets A_s[t]$
        \State $c \gets \begin{cases} p'_j & \text{if } a = j \\ p_{0,a} & \text{otherwise} \end{cases}$
        \State $\ell \gets \ell \OR (\bitfn(c, s{-}1) \SHL t)$
    \EndFor
    \State $w \gets \gc^{-1}(T_{(e,d)}(\ell))$ \Comment{Encode: transform and Gray decode}
    \State $h_1 \gets (h_1 \SHL k_s) \OR w$
    \State $e \gets e \XOR \mathrm{rotL}(\entry(w), d{+}1, k_s)$ \Comment{Update state}
    \State $d \gets (d + \dir(k_s, w) + 1) \mod k_s$
    \If{$s > 1$ and $k_{s-1} > k_s$} \Comment{Embed if axes activate}
        \State $(e, d) \gets \mathrm{Embed}(A_s, A_{s-1}, e, d)$
    \EndIf
\EndFor
\Return $h_1$
\end{algorithmic}
\end{algorithm}

\subsection{Next index}

It is tremendously valuable to be able to map a whole domain $P_k(\mathbf{m})$
to its Hilbert indices. That calculation greatly reduces the total amount
of computation compared to computing each Hilbert index separately.

Maintain a stack of transforms $(e_s,d_s)$ and current rankings $w_s$.
Walk $w_s$ for each child cube.

This reduces the total computation to about $8+10k$ integer operations per
index. And more memory.

Finding the neighboring point in $P_k(\mathbf{m})$ is doable, and there is some
advantage, but it's much less helpful. We can calculate or measure how much
less helpful it is.

Prefix scan algorithm. Could the linearity of the BRGC and its transforms
mean that we can incrementally update the index given an incremental change
to the point?

\section{Experimental Validation}

\begin{table}[htbp]
\centering
\caption{Hilbert Curve Variants for Experiments}
\label{tab:curve-variants}
\begin{tabular}{c p{3cm} c c c p{3cm}}
\hline
Label & Construction & Gray code & Transforms & Lattice continuous & Notes \\
\hline
Hamilton-CHI & Removal of inactive indices & \brgc & Hamilton's $T_{e,d}$ & No & Algorithm from Hamilton and Rao-Chaplin~\cite{hamilton2008compact}. \\
\hline
LC-BRGC & This article & \brgc & Tabular & Yes & Uses \brgc but solves for the transforms \\
\hline
LC-Balanced & This article & Balanced & Tabular & Yes & The best known variant for locality \\
\hline
LC-Random & This article & Random & Tabular & Yes & As a robustness check \\
\hline
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Selected Domains for Experiments}
\label{tab:domains}
\begin{tabular}{lrrrrr}
\hline
Domain ID & $m=(m_x,m_y)$ & Grid size & Aspect Ratio & Total bits $M$ & Points $N=2^M$ \\
\hline
D0 & (9,9) & 512 x 512 & 1 : 1 & 18 & 262,144 \\
D1 & (11, 7) & 2048 x 128 & 16 : 1 & 18 & 262,144 \\
D2 & (12, 6) & 4096 x 64 & 64 : 1 & 18 & 262,144 \\
D3 & (13, 5) & 8192 x 32 & 256 : 1 & 18 & 262,144 \\
\hline
\end{tabular}
\end{table}

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{discontinuities_by_perimeter_2d}
\caption{Size of the largest discontinuity by perimeter for 2D domains for Compact Hilbert Indices
from Hamilton and Rao-Chaplin~\cite{hamilton2008compact}.}
\label{fig:discontinuities-perimeter-2d}
\end{figure}

\begin{table}[htbp]
\centering
\label{tab:locality-metrics}
\begin{tabular}{llrrrr}
\toprule
Domain & Aspect & Hamilton $\mathrm{WL}_\infty$ & LC-CHI $\mathrm{WL}_\infty$ & Hamilton WBA & LC-CHI WBA \\
\midrule
$512 \times 512$   & 1:1   & 4.75 & 4.75  & 2.29 & 2.29 \\
$2048 \times 128$  & 16:1  & 442  & 4.75  & 435  & 2.29 \\
$4096 \times 64$   & 64:1  & 384  & 7.62  & 416  & 2.29 \\
$8192 \times 32$   & 256:1 & 512  & 26.2  & 528  & 2.33 \\
\bottomrule
\end{tabular}
\caption{Worst-case locality metrics for Hamilton-CHI and LC-BRGC across rectangular domains.
Key metrics: $\mathrm{WL}_\infty$ (Chebyshev locality), $\mathrm{WL}_2$ (Euclidean locality),
$\mathrm{WL}_1$ (Manhattan locality), WBA (bounding box area ratio), WBP (bounding box perimeter ratio).}
\end{table}


\begin{table}[htpb]
\centering
\label{tab:bounding-box-stats}
\begin{tabular}{llrrrrr}
\toprule
Domain & Curve & Block size $B$ & Mean $\frac{\text{bbox}}{B}$ & P95 $\frac{\text{bbox}}{B}$ & Max $\frac{\text{bbox}}{B}$ & Max $\frac{\text{peri}}{\sqrt{B}}$ \\
\midrule
512$\times$512 & Hamilton & 32 & 1 & 1 & 1 & 4.24 \\
 & LC-BRGC & 32 & 1 & 1 & 1 & 4.24 \\
 & Hamilton & 100 & 1.35 & 1.68 & 1.92 & 5.6 \\
 & LC-BRGC & 100 & 1.35 & 1.68 & 1.92 & 5.6 \\
 & Hamilton & 500 & 1.41 & 1.79 & 2.05 & 5.72 \\
 & LC-BRGC & 500 & 1.41 & 1.79 & 2.05 & 5.72 \\
 & Hamilton & 1024 & 1 & 1 & 1 & 4 \\
 & LC-BRGC & 1024 & 1 & 1 & 1 & 4 \\
\addlinespace
2048$\times$128 & Hamilton & 32 & 1 & 1 & 1 & 4.24 \\
 & LC-BRGC & 32 & 1 & 1 & 1 & 4.24 \\
 & Hamilton & 100 & 2.33 & 1.68 & 174.08 & 52.8 \\
 & LC-BRGC & 100 & 1.35 & 1.68 & 1.92 & 5.6 \\
 & Hamilton & 500 & 2.43 & 2.05 & 40.96 & 25.76 \\
 & LC-BRGC & 500 & 1.41 & 1.79 & 2.05 & 5.72 \\
 & Hamilton & 1024 & 1 & 1 & 1 & 4 \\
 & LC-BRGC & 1024 & 1 & 1 & 1 & 4 \\
\addlinespace
4096$\times$64 & Hamilton & 32 & 1 & 1 & 1 & 4.24 \\
 & LC-BRGC & 32 & 1 & 1 & 1 & 4.24 \\
 & Hamilton & 100 & 2.38 & 1.92 & 51.2 & 28.8 \\
 & LC-BRGC & 100 & 1.35 & 1.68 & 1.92 & 5.6 \\
 & Hamilton & 500 & 2.45 & 10.24 & 10.24 & 12.88 \\
 & LC-BRGC & 500 & 1.4 & 1.79 & 2.05 & 5.72 \\
 & Hamilton & 1024 & 1 & 1 & 1 & 4 \\
 & LC-BRGC & 1024 & 1 & 1 & 1 & 4 \\
\addlinespace
8192$\times$32 & Hamilton & 32 & 1 & 1 & 1 & 4.24 \\
 & LC-BRGC & 32 & 1 & 1 & 1 & 4.24 \\
 & Hamilton & 100 & 2.39 & 12.8 & 12.8 & 14.4 \\
 & LC-BRGC & 100 & 1.34 & 1.68 & 1.92 & 5.6 \\
 & Hamilton & 500 & 2.31 & 4.1 & 4.1 & 8.59 \\
 & LC-BRGC & 500 & 1.49 & 2.05 & 2.05 & 5.72 \\
 & Hamilton & 1024 & 1 & 1 & 1 & 4 \\
 & LC-BRGC & 1024 & 1 & 1 & 1 & 4 \\
\bottomrule
\end{tabular}
\caption{This is the “indexing application” table. It is more intuitive than 
WBA/WBP
WBA/WBP and more directly tied to how SFCs are used to build blocks (e.g., R-tree leaves). Haverkort motivates this style of evaluation by grouping consecutive points into blocks and measuring block bounding boxes. Computation: deterministic (no sampling) if you just partition the full curve into consecutive blocks of size B. Report both average and max because seam jumps tend to show up in the max/tails.}
\end{table}

\begin{table}[htpb]
\centering
\label{tab:range-query}
\begin{tabular}{lrrrrl}
\toprule
Curve & Query window & Mean clusters & P95 clusters & Max clusters & Method \\
\midrule
Hamilton & 4$\times$4 & 3.97 & 6 & 7 & exhaustive (249,673) \\
LC-BRGC & 4$\times$4 & 3.97 & 6 & 6 & exhaustive (249,673) \\
LC-Balanced & 4$\times$4 & 3.97 & 6 & 6 & exhaustive (249,673) \\
LC-Random & 4$\times$4 & 3.97 & 6 & 6 & exhaustive (249,673) \\
\addlinespace
Hamilton & 8$\times$8 & 7.92 & 13 & 14 & exhaustive (233,073) \\
LC-BRGC & 8$\times$8 & 7.94 & 13 & 14 & exhaustive (233,073) \\
LC-Balanced & 8$\times$8 & 7.94 & 13 & 14 & exhaustive (233,073) \\
LC-Random & 8$\times$8 & 7.94 & 13 & 14 & exhaustive (233,073) \\
\addlinespace
Hamilton & 16$\times$16 & 15.83 & 26 & 29 & exhaustive (199,969) \\
LC-BRGC & 16$\times$16 & 15.85 & 26 & 26 & exhaustive (199,969) \\
LC-Balanced & 16$\times$16 & 15.85 & 26 & 26 & exhaustive (199,969) \\
LC-Random & 16$\times$16 & 15.85 & 26 & 26 & exhaustive (199,969) \\
\addlinespace
Hamilton & 64$\times$4 & 33.64 & 53 & 55 & exhaustive (246,013) \\
LC-BRGC & 64$\times$4 & 33.56 & 54 & 59 & exhaustive (246,013) \\
LC-Balanced & 64$\times$4 & 33.56 & 54 & 59 & exhaustive (246,013) \\
LC-Random & 64$\times$4 & 33.56 & 54 & 59 & exhaustive (246,013) \\
\addlinespace
Hamilton & 4$\times$64 & 32.06 & 52 & 60 & exhaustive (4,093) \\
LC-BRGC & 4$\times$64 & 31.99 & 51 & 51 & exhaustive (4,093) \\
LC-Balanced & 4$\times$64 & 31.99 & 51 & 51 & exhaustive (4,093) \\
LC-Random & 4$\times$64 & 31.99 & 51 & 51 & exhaustive (4,093) \\
\addlinespace
Hamilton & 32$\times$32 & 31.47 & 50 & 54 & exhaustive (134,145) \\
LC-BRGC & 32$\times$32 & 31.57 & 50 & 53 & exhaustive (134,145) \\
LC-Balanced & 32$\times$32 & 31.57 & 50 & 53 & exhaustive (134,145) \\
LC-Random & 32$\times$32 & 31.57 & 50 & 53 & exhaustive (134,145) \\
\bottomrule
\end{tabular}
\caption{This is a range query, done by exhaustive enumeration. This counts the number of clusters within a query window, but it doesn't count the size
of the gaps, so it doesn't differentiate strongly between breaks in locality
and large adjacency skips~\cite{moon2001analysis}.}
\end{table}


\section{Conclusion}
We have a new algorithm to find Hilbert curves.

We have a new algorithm to generate a sequence of points ranked
by their Hilbert index.

We have a new algorithm to construct Hilbert curves of unequal side
lengths that are lattice-continuous.


\bibliographystyle{plain}
\bibliography{article}

\end{document}
